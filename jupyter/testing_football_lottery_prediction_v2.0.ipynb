{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymysql.cursors\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "import re\n",
    "import datetime\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 训练"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 获取让球的赔率信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection = pymysql.connect(host='localhost', user='root', password='breadt@2019', db='breadt-football-ml', charset='utf8mb4', cursorclass=pymysql.cursors.DictCursor)\n",
    "with connection.cursor() as cursor:\n",
    "    sql = 'select * from `breadt_football_offset_info`;'\n",
    "    cursor.execute(sql)\n",
    "    rows = cursor.fetchall()\n",
    "    \n",
    "    train_game_offset_df = pd.DataFrame(rows)\n",
    "    \n",
    "    connection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['两半/三', '半/一', '两球', '一球', '受平/半', '平/半', '两/两半', '半球', '球半/两',\n",
       "       '球半', '受半球', '受半/一', '受一/球半', '受一球', '一/球半', '平手', '受球半', '受球半/两',\n",
       "       '受两球', '三球', '两半', '受两/两半', '受三球', '三/三半', '受三/三半', '六球', '四球',\n",
       "       '四半', '受两半', '八半', '受两半/三', '三半/四', '三半', '受六球', '受四半/五', '受五半/六',\n",
       "       '五球', '受三半', '四/四半', '五半', '受四/四半', '四半/五', '受六半', '六半/七', '七半',\n",
       "       '受四半', '受五/五半', '受六/六半', '受四球', '六半', '受三半/四', '七/七半', '受五半'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 453,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_game_offset_df['new_offset'].drop_duplicates().values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [],
   "source": [
    "def take_value_from_work(row):\n",
    "    map = {\n",
    "        '两半/三': -2.75, \n",
    "        '半/一': -0.75, \n",
    "        '两球': -2, \n",
    "        '一球': -1, \n",
    "        '受平/半': 0.25, \n",
    "        '平/半': -0.25, \n",
    "        '两/两半': -2.25, \n",
    "        '半球': -0.5,\n",
    "        '球半/两': -1.75,\n",
    "        '球半': -1.5,\n",
    "        '受半球': 0.5, \n",
    "        '受半/一': 0.75, \n",
    "        '受一/球半': 1.25, \n",
    "        '受一球': 1, \n",
    "        '一/球半': -1.25, \n",
    "        '平手': 0, \n",
    "        '受球半': 1.5, \n",
    "        '受球半/两': 1.75,\n",
    "        '受两球': 2, \n",
    "        '三球': -3, \n",
    "        '两半': -2.5, \n",
    "        '受两/两半': 2.25, \n",
    "        '受三球': 3, \n",
    "        '三/三半': -3.25, \n",
    "        '受三/三半': 3.25, \n",
    "        '六球': -6, \n",
    "        '四球': -4,\n",
    "        '四半': -4.5, \n",
    "        '受两半': 2.5, \n",
    "        '八半': -8.5, \n",
    "        '受两半/三': 2.75, \n",
    "        '三半/四': -3.75, \n",
    "        '三半': -3.5, \n",
    "        '受六球': 6, \n",
    "        '受四半/五': 4.75, \n",
    "        '受五半/六': 5.75,\n",
    "        '五球': -5, \n",
    "        '受三半': 3.5, \n",
    "        '四/四半': -4.25, \n",
    "        '五半': -5.5, \n",
    "        '受四/四半': 4.25, \n",
    "        '四半/五': -4.75, \n",
    "        '受六半': 6.5, \n",
    "        '六半/七': -6.75, \n",
    "        '七半': -7.5,\n",
    "        '受四半': 4.5, \n",
    "        '受五/五半': 5.25, \n",
    "        '受六/六半': 6.25, \n",
    "        '受四球': 4, \n",
    "        '六半': -6.5,\n",
    "        '受三半/四': 3.75, \n",
    "        '七/七半': -7.25,\n",
    "        '受五半': 5.5\n",
    "    }\n",
    "    \n",
    "    v = map[row.new_offset]\n",
    "    \n",
    "    # 原来只需要返回v这里，我特别做处理\n",
    "#     if v is not None:\n",
    "#         num = v/0.25\n",
    "#         if num % 4 > 0:\n",
    "#             if num > 0:\n",
    "#                 if num % 4 == 3:\n",
    "#                     return (num + 1)*0.25\n",
    "#                 elif num % 4 == 2\n",
    "#                 return (num - 1)*0.25\n",
    "#             else:\n",
    "#                 return (num + 1)*0.25\n",
    "    \n",
    "    return v\n",
    "\n",
    "train_game_offset_df['new_offset_val'] = train_game_offset_df.apply(lambda row: take_value_from_work(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>id</th>\n",
       "      <th>init_host</th>\n",
       "      <th>init_offset</th>\n",
       "      <th>init_visit</th>\n",
       "      <th>matchid</th>\n",
       "      <th>new_host</th>\n",
       "      <th>new_host_rate</th>\n",
       "      <th>new_offset</th>\n",
       "      <th>new_visit</th>\n",
       "      <th>new_visit_rate</th>\n",
       "      <th>new_offset_val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>澳门</td>\n",
       "      <td>1</td>\n",
       "      <td>0.82</td>\n",
       "      <td>三/三半</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1235399</td>\n",
       "      <td>0.90</td>\n",
       "      <td>50.26</td>\n",
       "      <td>两半/三</td>\n",
       "      <td>0.92</td>\n",
       "      <td>49.74</td>\n",
       "      <td>-2.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>澳门</td>\n",
       "      <td>2</td>\n",
       "      <td>1.06</td>\n",
       "      <td>半/一</td>\n",
       "      <td>0.70</td>\n",
       "      <td>1765346</td>\n",
       "      <td>0.86</td>\n",
       "      <td>50.53</td>\n",
       "      <td>半/一</td>\n",
       "      <td>0.90</td>\n",
       "      <td>49.47</td>\n",
       "      <td>-0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>澳门</td>\n",
       "      <td>3</td>\n",
       "      <td>0.82</td>\n",
       "      <td>两球</td>\n",
       "      <td>0.94</td>\n",
       "      <td>1765347</td>\n",
       "      <td>0.81</td>\n",
       "      <td>51.86</td>\n",
       "      <td>两球</td>\n",
       "      <td>0.95</td>\n",
       "      <td>48.14</td>\n",
       "      <td>-2.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>澳门</td>\n",
       "      <td>4</td>\n",
       "      <td>0.76</td>\n",
       "      <td>一球</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1765348</td>\n",
       "      <td>0.88</td>\n",
       "      <td>50.00</td>\n",
       "      <td>一球</td>\n",
       "      <td>0.88</td>\n",
       "      <td>50.00</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>澳门</td>\n",
       "      <td>5</td>\n",
       "      <td>0.70</td>\n",
       "      <td>受平/半</td>\n",
       "      <td>1.06</td>\n",
       "      <td>1765349</td>\n",
       "      <td>0.72</td>\n",
       "      <td>54.26</td>\n",
       "      <td>受平/半</td>\n",
       "      <td>1.04</td>\n",
       "      <td>45.74</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>澳门</td>\n",
       "      <td>6</td>\n",
       "      <td>0.80</td>\n",
       "      <td>平/半</td>\n",
       "      <td>0.96</td>\n",
       "      <td>1765350</td>\n",
       "      <td>0.96</td>\n",
       "      <td>47.87</td>\n",
       "      <td>平/半</td>\n",
       "      <td>0.80</td>\n",
       "      <td>52.13</td>\n",
       "      <td>-0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>澳门</td>\n",
       "      <td>7</td>\n",
       "      <td>0.68</td>\n",
       "      <td>两/两半</td>\n",
       "      <td>1.08</td>\n",
       "      <td>1765351</td>\n",
       "      <td>0.74</td>\n",
       "      <td>53.72</td>\n",
       "      <td>两/两半</td>\n",
       "      <td>1.02</td>\n",
       "      <td>46.28</td>\n",
       "      <td>-2.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>澳门</td>\n",
       "      <td>8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>平/半</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1765352</td>\n",
       "      <td>0.86</td>\n",
       "      <td>50.53</td>\n",
       "      <td>半球</td>\n",
       "      <td>0.90</td>\n",
       "      <td>49.47</td>\n",
       "      <td>-0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>澳门</td>\n",
       "      <td>9</td>\n",
       "      <td>0.98</td>\n",
       "      <td>半球</td>\n",
       "      <td>0.78</td>\n",
       "      <td>1765354</td>\n",
       "      <td>1.16</td>\n",
       "      <td>42.55</td>\n",
       "      <td>半球</td>\n",
       "      <td>0.60</td>\n",
       "      <td>57.45</td>\n",
       "      <td>-0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>澳门</td>\n",
       "      <td>10</td>\n",
       "      <td>0.90</td>\n",
       "      <td>两/两半</td>\n",
       "      <td>0.92</td>\n",
       "      <td>1765358</td>\n",
       "      <td>1.06</td>\n",
       "      <td>46.07</td>\n",
       "      <td>两球</td>\n",
       "      <td>0.76</td>\n",
       "      <td>53.93</td>\n",
       "      <td>-2.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>澳门</td>\n",
       "      <td>11</td>\n",
       "      <td>0.84</td>\n",
       "      <td>球半/两</td>\n",
       "      <td>1.02</td>\n",
       "      <td>1765886</td>\n",
       "      <td>1.06</td>\n",
       "      <td>46.63</td>\n",
       "      <td>球半/两</td>\n",
       "      <td>0.80</td>\n",
       "      <td>53.37</td>\n",
       "      <td>-1.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>澳门</td>\n",
       "      <td>12</td>\n",
       "      <td>1.00</td>\n",
       "      <td>平/半</td>\n",
       "      <td>0.86</td>\n",
       "      <td>1765887</td>\n",
       "      <td>0.98</td>\n",
       "      <td>48.70</td>\n",
       "      <td>平/半</td>\n",
       "      <td>0.88</td>\n",
       "      <td>51.30</td>\n",
       "      <td>-0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>澳门</td>\n",
       "      <td>13</td>\n",
       "      <td>1.08</td>\n",
       "      <td>平/半</td>\n",
       "      <td>0.78</td>\n",
       "      <td>1765888</td>\n",
       "      <td>1.00</td>\n",
       "      <td>48.19</td>\n",
       "      <td>平/半</td>\n",
       "      <td>0.86</td>\n",
       "      <td>51.81</td>\n",
       "      <td>-0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>澳门</td>\n",
       "      <td>14</td>\n",
       "      <td>1.06</td>\n",
       "      <td>球半/两</td>\n",
       "      <td>0.80</td>\n",
       "      <td>1765889</td>\n",
       "      <td>0.91</td>\n",
       "      <td>50.52</td>\n",
       "      <td>球半</td>\n",
       "      <td>0.95</td>\n",
       "      <td>49.48</td>\n",
       "      <td>-1.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>澳门</td>\n",
       "      <td>15</td>\n",
       "      <td>0.92</td>\n",
       "      <td>半/一</td>\n",
       "      <td>0.94</td>\n",
       "      <td>1765890</td>\n",
       "      <td>0.72</td>\n",
       "      <td>55.44</td>\n",
       "      <td>半/一</td>\n",
       "      <td>1.14</td>\n",
       "      <td>44.56</td>\n",
       "      <td>-0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>澳门</td>\n",
       "      <td>16</td>\n",
       "      <td>0.92</td>\n",
       "      <td>受半球</td>\n",
       "      <td>0.94</td>\n",
       "      <td>1765891</td>\n",
       "      <td>0.86</td>\n",
       "      <td>51.81</td>\n",
       "      <td>受半球</td>\n",
       "      <td>1.00</td>\n",
       "      <td>48.19</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>澳门</td>\n",
       "      <td>17</td>\n",
       "      <td>0.86</td>\n",
       "      <td>受半球</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1765892</td>\n",
       "      <td>1.05</td>\n",
       "      <td>46.89</td>\n",
       "      <td>受半球</td>\n",
       "      <td>0.81</td>\n",
       "      <td>53.11</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>澳门</td>\n",
       "      <td>18</td>\n",
       "      <td>0.80</td>\n",
       "      <td>平/半</td>\n",
       "      <td>1.06</td>\n",
       "      <td>1765893</td>\n",
       "      <td>0.80</td>\n",
       "      <td>53.37</td>\n",
       "      <td>平/半</td>\n",
       "      <td>1.06</td>\n",
       "      <td>46.63</td>\n",
       "      <td>-0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>澳门</td>\n",
       "      <td>19</td>\n",
       "      <td>0.88</td>\n",
       "      <td>受一球</td>\n",
       "      <td>0.98</td>\n",
       "      <td>1765894</td>\n",
       "      <td>1.03</td>\n",
       "      <td>47.41</td>\n",
       "      <td>受半/一</td>\n",
       "      <td>0.83</td>\n",
       "      <td>52.59</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>澳门</td>\n",
       "      <td>20</td>\n",
       "      <td>1.08</td>\n",
       "      <td>平/半</td>\n",
       "      <td>0.78</td>\n",
       "      <td>1765895</td>\n",
       "      <td>0.96</td>\n",
       "      <td>49.22</td>\n",
       "      <td>平/半</td>\n",
       "      <td>0.90</td>\n",
       "      <td>50.78</td>\n",
       "      <td>-0.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   company  id  init_host init_offset  init_visit  matchid  new_host  \\\n",
       "0       澳门   1       0.82        三/三半        1.00  1235399      0.90   \n",
       "1       澳门   2       1.06         半/一        0.70  1765346      0.86   \n",
       "2       澳门   3       0.82          两球        0.94  1765347      0.81   \n",
       "3       澳门   4       0.76          一球        1.00  1765348      0.88   \n",
       "4       澳门   5       0.70        受平/半        1.06  1765349      0.72   \n",
       "5       澳门   6       0.80         平/半        0.96  1765350      0.96   \n",
       "6       澳门   7       0.68        两/两半        1.08  1765351      0.74   \n",
       "7       澳门   8       0.76         平/半        1.00  1765352      0.86   \n",
       "8       澳门   9       0.98          半球        0.78  1765354      1.16   \n",
       "9       澳门  10       0.90        两/两半        0.92  1765358      1.06   \n",
       "10      澳门  11       0.84        球半/两        1.02  1765886      1.06   \n",
       "11      澳门  12       1.00         平/半        0.86  1765887      0.98   \n",
       "12      澳门  13       1.08         平/半        0.78  1765888      1.00   \n",
       "13      澳门  14       1.06        球半/两        0.80  1765889      0.91   \n",
       "14      澳门  15       0.92         半/一        0.94  1765890      0.72   \n",
       "15      澳门  16       0.92         受半球        0.94  1765891      0.86   \n",
       "16      澳门  17       0.86         受半球        1.00  1765892      1.05   \n",
       "17      澳门  18       0.80         平/半        1.06  1765893      0.80   \n",
       "18      澳门  19       0.88         受一球        0.98  1765894      1.03   \n",
       "19      澳门  20       1.08         平/半        0.78  1765895      0.96   \n",
       "\n",
       "    new_host_rate new_offset  new_visit  new_visit_rate  new_offset_val  \n",
       "0           50.26       两半/三       0.92           49.74           -2.75  \n",
       "1           50.53        半/一       0.90           49.47           -0.75  \n",
       "2           51.86         两球       0.95           48.14           -2.00  \n",
       "3           50.00         一球       0.88           50.00           -1.00  \n",
       "4           54.26       受平/半       1.04           45.74            0.25  \n",
       "5           47.87        平/半       0.80           52.13           -0.25  \n",
       "6           53.72       两/两半       1.02           46.28           -2.25  \n",
       "7           50.53         半球       0.90           49.47           -0.50  \n",
       "8           42.55         半球       0.60           57.45           -0.50  \n",
       "9           46.07         两球       0.76           53.93           -2.00  \n",
       "10          46.63       球半/两       0.80           53.37           -1.75  \n",
       "11          48.70        平/半       0.88           51.30           -0.25  \n",
       "12          48.19        平/半       0.86           51.81           -0.25  \n",
       "13          50.52         球半       0.95           49.48           -1.50  \n",
       "14          55.44        半/一       1.14           44.56           -0.75  \n",
       "15          51.81        受半球       1.00           48.19            0.50  \n",
       "16          46.89        受半球       0.81           53.11            0.50  \n",
       "17          53.37        平/半       1.06           46.63           -0.25  \n",
       "18          47.41       受半/一       0.83           52.59            0.75  \n",
       "19          49.22        平/半       0.90           50.78           -0.25  "
      ]
     },
     "execution_count": 455,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_game_offset_df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 获取全量的竞彩比赛列表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection = pymysql.connect(host='localhost', user='root', password='breadt@2019', db='breadt-football-ml', charset='utf8mb4', cursorclass=pymysql.cursors.DictCursor)\n",
    "with connection.cursor() as cursor:\n",
    "    sql = 'select * from `breadt_football_game_list`;'\n",
    "    cursor.execute(sql)\n",
    "    rows = cursor.fetchall()\n",
    "    \n",
    "    train_game_list_df = pd.DataFrame(rows)\n",
    "    \n",
    "    connection.close()\n",
    "\n",
    "train_game_list_df['source'] = 'jc'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 获取全量的胜负彩比赛列表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection = pymysql.connect(host='localhost', user='root', password='breadt@2019', db='breadt-football-ml', charset='utf8mb4', cursorclass=pymysql.cursors.DictCursor)\n",
    "with connection.cursor() as cursor:\n",
    "    sql = 'select * from `breadt_lottery_info`;'\n",
    "    cursor.execute(sql)\n",
    "    rows = cursor.fetchall()\n",
    "    \n",
    "    train_lottery_game_list_df = pd.DataFrame(rows)\n",
    "    \n",
    "    connection.close()\n",
    "\n",
    "train_lottery_game_list_df['source'] = 'lottery'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 合并竞彩比赛列表和胜负彩比赛列表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = train_lottery_game_list_df.drop(['issue'], axis=1)\n",
    "df = pd.concat([train_game_list_df, tmp])\n",
    "df = df[['matchid', 'game', 'home_team', 'visit_team', 'gs', 'gd', 'gn', 'time', 'result', 'win_bet_return', 'draw_bet_return', 'lose_bet_return', 'source']]\n",
    "df = df.drop_duplicates(subset=['matchid'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **设定训练范围** 并处理数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# match_group = ['澳超', '英超', '德甲', '德乙', '法甲', '西甲', '意甲', '日职', '英甲', '英冠', '苏超', '法乙', '葡超', '荷甲', '荷乙', '韩K联', '瑞典超', '挪超', '美职', '日乙', '俄超', '比甲', '瑞典甲', '法丙', '挪甲', '英乙', '苏冠', '巴甲', '智利甲', '墨超', '智利乙', '阿甲', '欧冠', '欧罗巴']\n",
    "match_group = ['澳超', '英超', '德甲', '德乙', '法甲', '西甲', '意甲', '日职', '英甲', '英冠', '苏超', '法乙', '葡超', '荷甲', '荷乙', '韩K联', '瑞典超', '挪超', '美职', '日乙', '俄超', '比甲', '瑞典甲', '法丙', '挪甲', '英乙', '苏冠', '巴甲', '智利甲', '墨超', '智利乙', '阿甲']\n",
    "match_df = df[(df['game'].isin(match_group))]\n",
    "match_df = match_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 对team做encode 这个encoder后面预测的时候还会用到\n",
    "teams = list(set(df['home_team'].values) | set(df['visit_team'].values))\n",
    "team_encoder = preprocessing.LabelEncoder()\n",
    "team_encoder.fit(teams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_team(df):\n",
    "    df['home_team_encoder'] = team_encoder.transform(df['home_team'])\n",
    "    df['visit_team_encoder'] = team_encoder.transform(df['visit_team'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 比赛名称encode\n",
    "games = list(set(match_df['game'].values))\n",
    "game_encoder = preprocessing.LabelEncoder()\n",
    "game_encoder.fit(games)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_game(df):\n",
    "    df['game_encoder'] = game_encoder.transform(df['game'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_df['year'] = match_df.apply(lambda row: row.time.year, axis=1)\n",
    "match_df['month'] = match_df.apply(lambda row: row.time.month, axis=1)\n",
    "match_df['day'] = match_df.apply(lambda row: row.time.day, axis=1)\n",
    "match_df['fix_result'] = match_df.apply(lambda row: int(row.result) if row.result < 3 else 2, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_df = encode_team(match_df)\n",
    "match_df = encode_game(match_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 43477 entries, 1 to 12650\n",
      "Data columns (total 20 columns):\n",
      "matchid               43477 non-null int64\n",
      "game                  43477 non-null object\n",
      "home_team             43477 non-null object\n",
      "visit_team            43477 non-null object\n",
      "gs                    43477 non-null int64\n",
      "gd                    43477 non-null int64\n",
      "gn                    43477 non-null int64\n",
      "time                  43477 non-null datetime64[ns]\n",
      "result                43477 non-null int64\n",
      "win_bet_return        43477 non-null float64\n",
      "draw_bet_return       43477 non-null float64\n",
      "lose_bet_return       43477 non-null float64\n",
      "source                43477 non-null object\n",
      "year                  43477 non-null int64\n",
      "month                 43477 non-null int64\n",
      "day                   43477 non-null int64\n",
      "fix_result            43477 non-null int64\n",
      "home_team_encoder     43477 non-null int64\n",
      "visit_team_encoder    43477 non-null int64\n",
      "game_encoder          43477 non-null int64\n",
      "dtypes: datetime64[ns](1), float64(3), int64(12), object(4)\n",
      "memory usage: 7.0+ MB\n"
     ]
    }
   ],
   "source": [
    "match_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 获取特征数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection = pymysql.connect(host='localhost', user='root', password='breadt@2019', db='breadt-football-ml', charset='utf8mb4', cursorclass=pymysql.cursors.DictCursor)\n",
    "with connection.cursor() as cursor:\n",
    "    sql = 'select * from `breadt_football_recent_feature_info`;'\n",
    "    cursor.execute(sql)\n",
    "    rows = cursor.fetchall()\n",
    "    \n",
    "    train_feature_df = pd.DataFrame(rows)\n",
    "    \n",
    "    connection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def take_goal_info(prefix, df):\n",
    "    target_cols = [\n",
    "        '_0_1_gd', \n",
    "        '_0_1_gs', \n",
    "        '_0_gd', \n",
    "        '_0_gs', \n",
    "        '_1_gd', \n",
    "        '_1_gs',\n",
    "        '_2_3_gd', \n",
    "        '_2_3_gs', \n",
    "        '_2_gd', \n",
    "        '_2_gs', \n",
    "        '_3_gd', \n",
    "        '_3_gs',\n",
    "        '_4_gd', \n",
    "        '_4_gs', \n",
    "        '_5_gd', \n",
    "        '_5_gs', \n",
    "        '_6_gd', \n",
    "        '_6_gs',\n",
    "        '_7_gd', \n",
    "        '_7_gs', \n",
    "        '_ab_4_gd', \n",
    "        '_ab_4_gs',\n",
    "        '_abs_draw', \n",
    "        '_abs_lose', \n",
    "        '_abs_win']\n",
    "\n",
    "    for k in target_cols:\n",
    "        df[prefix + k + '_rate'] = df[prefix + k] / df[prefix + '_count']\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def take_goal_pref_info(prefix, df):\n",
    "    target_cols = [\n",
    "        '_draw', '_g', '_gd',\n",
    "        '_gs', '_lose', '_win',\n",
    "    ]\n",
    "\n",
    "    for k in target_cols:\n",
    "        df[prefix + k + '_rate'] = df[prefix + k] / df[prefix + '_count']\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feature_df = take_goal_info('h', train_feature_df)\n",
    "train_feature_df = take_goal_info('v', train_feature_df)\n",
    "\n",
    "train_feature_df = take_goal_pref_info('h_host', train_feature_df)\n",
    "train_feature_df = take_goal_pref_info('v_visit', train_feature_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 所有球队的主客场进球平均数\n",
    "\n",
    "train_feature_df['h_avg_abs_gs'] = train_feature_df['h_abs_gs'].sum() / train_feature_df['h_count'].sum()\n",
    "train_feature_df['h_avg_abs_gd'] = train_feature_df['h_abs_gd'].sum() / train_feature_df['h_count'].sum()\n",
    "train_feature_df['v_avg_abs_gs'] = train_feature_df['v_abs_gs'].sum() / train_feature_df['v_count'].sum()\n",
    "train_feature_df['v_avg_abs_gd'] = train_feature_df['v_abs_gd'].sum() / train_feature_df['v_count'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feature_df['h_avg_abs_win'] = train_feature_df['h_abs_win'].sum() / train_feature_df['h_count'].sum()\n",
    "train_feature_df['h_avg_abs_draw'] = train_feature_df['h_abs_draw'].sum() / train_feature_df['h_count'].sum()\n",
    "train_feature_df['h_avg_abs_lose'] = train_feature_df['h_abs_lose'].sum() / train_feature_df['h_count'].sum()\n",
    "\n",
    "train_feature_df['v_avg_abs_win'] = train_feature_df['v_abs_win'].sum() / train_feature_df['v_count'].sum()\n",
    "train_feature_df['v_avg_abs_draw'] = train_feature_df['v_abs_draw'].sum() / train_feature_df['v_count'].sum()\n",
    "train_feature_df['v_avg_abs_lose'] = train_feature_df['v_abs_lose'].sum() / train_feature_df['v_count'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 获取赔率信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection = pymysql.connect(host='localhost', user='root', password='breadt@2019', db='breadt-football-ml', charset='utf8mb4', cursorclass=pymysql.cursors.DictCursor)\n",
    "with connection.cursor() as cursor:\n",
    "    sql = 'select * from `breadt_match_odd_info`;'\n",
    "    cursor.execute(sql)\n",
    "    rows = cursor.fetchall()\n",
    "    \n",
    "    train_match_odd_df = pd.DataFrame(rows)\n",
    "    \n",
    "    connection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg_init_draw_odd</th>\n",
       "      <th>avg_init_lose_odd</th>\n",
       "      <th>avg_init_win_odd</th>\n",
       "      <th>avg_new_draw_kelly</th>\n",
       "      <th>avg_new_draw_odd</th>\n",
       "      <th>avg_new_draw_rate</th>\n",
       "      <th>avg_new_lose_kelly</th>\n",
       "      <th>avg_new_lose_odd</th>\n",
       "      <th>avg_new_lose_rate</th>\n",
       "      <th>avg_new_win_kelly</th>\n",
       "      <th>...</th>\n",
       "      <th>min_new_lose_kelly</th>\n",
       "      <th>min_new_lose_odd</th>\n",
       "      <th>min_new_lose_rate</th>\n",
       "      <th>min_new_win_kelly</th>\n",
       "      <th>min_new_win_odd</th>\n",
       "      <th>min_new_win_rate</th>\n",
       "      <th>min_pay_rate</th>\n",
       "      <th>std_draw</th>\n",
       "      <th>std_lose</th>\n",
       "      <th>std_win</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13.46</td>\n",
       "      <td>30.07</td>\n",
       "      <td>1.03</td>\n",
       "      <td>0.97</td>\n",
       "      <td>13.33</td>\n",
       "      <td>7.28</td>\n",
       "      <td>1.02</td>\n",
       "      <td>31.71</td>\n",
       "      <td>3.21</td>\n",
       "      <td>0.92</td>\n",
       "      <td>...</td>\n",
       "      <td>0.18</td>\n",
       "      <td>5.50</td>\n",
       "      <td>1.17</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1.00</td>\n",
       "      <td>66.71</td>\n",
       "      <td>0.83</td>\n",
       "      <td>1007.93</td>\n",
       "      <td>11029.60</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.38</td>\n",
       "      <td>4.29</td>\n",
       "      <td>1.75</td>\n",
       "      <td>0.91</td>\n",
       "      <td>3.43</td>\n",
       "      <td>26.55</td>\n",
       "      <td>0.91</td>\n",
       "      <td>4.46</td>\n",
       "      <td>20.50</td>\n",
       "      <td>0.91</td>\n",
       "      <td>...</td>\n",
       "      <td>0.76</td>\n",
       "      <td>3.70</td>\n",
       "      <td>16.79</td>\n",
       "      <td>0.79</td>\n",
       "      <td>1.50</td>\n",
       "      <td>48.58</td>\n",
       "      <td>0.83</td>\n",
       "      <td>1.83</td>\n",
       "      <td>12.46</td>\n",
       "      <td>0.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.72</td>\n",
       "      <td>14.49</td>\n",
       "      <td>1.14</td>\n",
       "      <td>0.92</td>\n",
       "      <td>6.97</td>\n",
       "      <td>13.17</td>\n",
       "      <td>0.95</td>\n",
       "      <td>15.31</td>\n",
       "      <td>6.19</td>\n",
       "      <td>0.91</td>\n",
       "      <td>...</td>\n",
       "      <td>0.48</td>\n",
       "      <td>7.80</td>\n",
       "      <td>3.38</td>\n",
       "      <td>0.85</td>\n",
       "      <td>1.05</td>\n",
       "      <td>69.75</td>\n",
       "      <td>0.83</td>\n",
       "      <td>37.80</td>\n",
       "      <td>1120.81</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.02</td>\n",
       "      <td>17.87</td>\n",
       "      <td>1.09</td>\n",
       "      <td>0.92</td>\n",
       "      <td>7.89</td>\n",
       "      <td>11.68</td>\n",
       "      <td>0.94</td>\n",
       "      <td>17.85</td>\n",
       "      <td>5.29</td>\n",
       "      <td>0.91</td>\n",
       "      <td>...</td>\n",
       "      <td>0.56</td>\n",
       "      <td>10.50</td>\n",
       "      <td>2.86</td>\n",
       "      <td>0.85</td>\n",
       "      <td>1.02</td>\n",
       "      <td>75.49</td>\n",
       "      <td>0.83</td>\n",
       "      <td>93.17</td>\n",
       "      <td>1417.25</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.98</td>\n",
       "      <td>6.79</td>\n",
       "      <td>1.42</td>\n",
       "      <td>0.91</td>\n",
       "      <td>4.06</td>\n",
       "      <td>22.43</td>\n",
       "      <td>0.92</td>\n",
       "      <td>7.17</td>\n",
       "      <td>12.88</td>\n",
       "      <td>0.91</td>\n",
       "      <td>...</td>\n",
       "      <td>0.69</td>\n",
       "      <td>5.35</td>\n",
       "      <td>9.54</td>\n",
       "      <td>0.84</td>\n",
       "      <td>1.30</td>\n",
       "      <td>59.57</td>\n",
       "      <td>0.83</td>\n",
       "      <td>4.23</td>\n",
       "      <td>90.73</td>\n",
       "      <td>0.14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   avg_init_draw_odd  avg_init_lose_odd  avg_init_win_odd  avg_new_draw_kelly  \\\n",
       "0              13.46              30.07              1.03                0.97   \n",
       "1               3.38               4.29              1.75                0.91   \n",
       "2               6.72              14.49              1.14                0.92   \n",
       "3               8.02              17.87              1.09                0.92   \n",
       "4               3.98               6.79              1.42                0.91   \n",
       "\n",
       "   avg_new_draw_odd  avg_new_draw_rate  avg_new_lose_kelly  avg_new_lose_odd  \\\n",
       "0             13.33               7.28                1.02             31.71   \n",
       "1              3.43              26.55                0.91              4.46   \n",
       "2              6.97              13.17                0.95             15.31   \n",
       "3              7.89              11.68                0.94             17.85   \n",
       "4              4.06              22.43                0.92              7.17   \n",
       "\n",
       "   avg_new_lose_rate  avg_new_win_kelly  ...  min_new_lose_kelly  \\\n",
       "0               3.21               0.92  ...                0.18   \n",
       "1              20.50               0.91  ...                0.76   \n",
       "2               6.19               0.91  ...                0.48   \n",
       "3               5.29               0.91  ...                0.56   \n",
       "4              12.88               0.91  ...                0.69   \n",
       "\n",
       "   min_new_lose_odd  min_new_lose_rate  min_new_win_kelly  min_new_win_odd  \\\n",
       "0              5.50               1.17               0.90             1.00   \n",
       "1              3.70              16.79               0.79             1.50   \n",
       "2              7.80               3.38               0.85             1.05   \n",
       "3             10.50               2.86               0.85             1.02   \n",
       "4              5.35               9.54               0.84             1.30   \n",
       "\n",
       "   min_new_win_rate  min_pay_rate  std_draw  std_lose  std_win  \n",
       "0             66.71          0.83   1007.93  11029.60     0.04  \n",
       "1             48.58          0.83      1.83     12.46     0.35  \n",
       "2             69.75          0.83     37.80   1120.81     0.05  \n",
       "3             75.49          0.83     93.17   1417.25     0.04  \n",
       "4             59.57          0.83      4.23     90.73     0.14  \n",
       "\n",
       "[5 rows x 47 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_match_odd_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 合并训练数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 30980 entries, 0 to 43278\n",
      "Columns: 217 entries, matchid to std_win\n",
      "dtypes: datetime64[ns](1), float64(200), int64(12), object(4)\n",
      "memory usage: 51.5+ MB\n"
     ]
    }
   ],
   "source": [
    "train_dataset_df = pd.merge(match_df, train_feature_df, on='matchid', how='left')\n",
    "train_dataset_df = pd.merge(train_dataset_df, train_match_odd_df, on='matchid', how='left')\n",
    "train_dataset_df = train_dataset_df.dropna()\n",
    "train_dataset_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['matchid', 'game', 'home_team', 'visit_team', 'gs', 'gd', 'gn',\n",
       "       'time', 'result', 'win_bet_return', 'draw_bet_return',\n",
       "       'lose_bet_return', 'source', 'year', 'month', 'day', 'fix_result',\n",
       "       'home_team_encoder', 'visit_team_encoder', 'game_encoder',\n",
       "       'h_0_1_gd', 'h_0_1_gs', 'h_0_gd', 'h_0_gs', 'h_1_gd', 'h_1_gs',\n",
       "       'h_2_3_gd', 'h_2_3_gs', 'h_2_gd', 'h_2_gs', 'h_3_gd', 'h_3_gs',\n",
       "       'h_4_gd', 'h_4_gs', 'h_5_gd', 'h_5_gs', 'h_6_gd', 'h_6_gs',\n",
       "       'h_7_gd', 'h_7_gs', 'h_ab_4_gd', 'h_ab_4_gs', 'h_abs_avg_g',\n",
       "       'h_abs_avg_gd', 'h_abs_avg_gs', 'h_abs_draw', 'h_abs_g',\n",
       "       'h_abs_gd', 'h_abs_gs', 'h_abs_lose', 'h_abs_win', 'h_count',\n",
       "       'h_host_count', 'h_host_draw', 'h_host_g', 'h_host_gd',\n",
       "       'h_host_gs', 'h_host_lose', 'h_host_win', 'id_x', 'v_0_1_gd',\n",
       "       'v_0_1_gs', 'v_0_gd', 'v_0_gs', 'v_1_gd', 'v_1_gs', 'v_2_3_gd',\n",
       "       'v_2_3_gs', 'v_2_gd', 'v_2_gs', 'v_3_gd', 'v_3_gs', 'v_4_gd',\n",
       "       'v_4_gs', 'v_5_gd', 'v_5_gs', 'v_6_gd', 'v_6_gs', 'v_7_gd',\n",
       "       'v_7_gs', 'v_ab_4_gd', 'v_ab_4_gs', 'v_abs_avg_g', 'v_abs_avg_gd',\n",
       "       'v_abs_avg_gs', 'v_abs_draw', 'v_abs_g', 'v_abs_gd', 'v_abs_gs',\n",
       "       'v_abs_lose', 'v_abs_win', 'v_count', 'v_visit_count',\n",
       "       'v_visit_draw', 'v_visit_g', 'v_visit_gd', 'v_visit_gs',\n",
       "       'v_visit_lose', 'v_visit_win', 'h_0_1_gd_rate', 'h_0_1_gs_rate',\n",
       "       'h_0_gd_rate', 'h_0_gs_rate', 'h_1_gd_rate', 'h_1_gs_rate',\n",
       "       'h_2_3_gd_rate', 'h_2_3_gs_rate', 'h_2_gd_rate', 'h_2_gs_rate',\n",
       "       'h_3_gd_rate', 'h_3_gs_rate', 'h_4_gd_rate', 'h_4_gs_rate',\n",
       "       'h_5_gd_rate', 'h_5_gs_rate', 'h_6_gd_rate', 'h_6_gs_rate',\n",
       "       'h_7_gd_rate', 'h_7_gs_rate', 'h_ab_4_gd_rate', 'h_ab_4_gs_rate',\n",
       "       'h_abs_draw_rate', 'h_abs_lose_rate', 'h_abs_win_rate',\n",
       "       'v_0_1_gd_rate', 'v_0_1_gs_rate', 'v_0_gd_rate', 'v_0_gs_rate',\n",
       "       'v_1_gd_rate', 'v_1_gs_rate', 'v_2_3_gd_rate', 'v_2_3_gs_rate',\n",
       "       'v_2_gd_rate', 'v_2_gs_rate', 'v_3_gd_rate', 'v_3_gs_rate',\n",
       "       'v_4_gd_rate', 'v_4_gs_rate', 'v_5_gd_rate', 'v_5_gs_rate',\n",
       "       'v_6_gd_rate', 'v_6_gs_rate', 'v_7_gd_rate', 'v_7_gs_rate',\n",
       "       'v_ab_4_gd_rate', 'v_ab_4_gs_rate', 'v_abs_draw_rate',\n",
       "       'v_abs_lose_rate', 'v_abs_win_rate', 'h_host_draw_rate',\n",
       "       'h_host_g_rate', 'h_host_gd_rate', 'h_host_gs_rate',\n",
       "       'h_host_lose_rate', 'h_host_win_rate', 'v_visit_draw_rate',\n",
       "       'v_visit_g_rate', 'v_visit_gd_rate', 'v_visit_gs_rate',\n",
       "       'v_visit_lose_rate', 'v_visit_win_rate', 'h_avg_abs_gs',\n",
       "       'h_avg_abs_gd', 'v_avg_abs_gs', 'v_avg_abs_gd', 'h_avg_abs_win',\n",
       "       'h_avg_abs_draw', 'h_avg_abs_lose', 'v_avg_abs_win',\n",
       "       'v_avg_abs_draw', 'v_avg_abs_lose', 'avg_init_draw_odd',\n",
       "       'avg_init_lose_odd', 'avg_init_win_odd', 'avg_new_draw_kelly',\n",
       "       'avg_new_draw_odd', 'avg_new_draw_rate', 'avg_new_lose_kelly',\n",
       "       'avg_new_lose_odd', 'avg_new_lose_rate', 'avg_new_win_kelly',\n",
       "       'avg_new_win_odd', 'avg_new_win_rate', 'avg_pay_rate',\n",
       "       'dispersion_draw', 'dispersion_lose', 'dispersion_win', 'id_y',\n",
       "       'max_init_draw_odd', 'max_init_lose_odd', 'max_init_win_odd',\n",
       "       'max_new_draw_kelly', 'max_new_draw_odd', 'max_new_draw_rate',\n",
       "       'max_new_lose_kelly', 'max_new_lose_odd', 'max_new_lose_rate',\n",
       "       'max_new_win_kelly', 'max_new_win_odd', 'max_new_win_rate',\n",
       "       'max_pay_rate', 'min_init_draw_odd', 'min_init_lose_odd',\n",
       "       'min_init_win_odd', 'min_new_draw_kelly', 'min_new_draw_odd',\n",
       "       'min_new_draw_rate', 'min_new_lose_kelly', 'min_new_lose_odd',\n",
       "       'min_new_lose_rate', 'min_new_win_kelly', 'min_new_win_odd',\n",
       "       'min_new_win_rate', 'min_pay_rate', 'std_draw', 'std_lose',\n",
       "       'std_win'], dtype=object)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset_df.columns.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## xgb regressor 尝试预测分差"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_df['fix_result'] = train_dataset_df['gs'] - train_dataset_df['gd']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "x_columns = [\n",
    "#     'win_bet_return', 'draw_bet_return', 'lose_bet_return', \n",
    "    'year', 'month',\n",
    "#     'home_team_encoder', 'visit_team_encoder', 'game_encoder',\n",
    "    \n",
    "    'h_avg_abs_gs',\n",
    "    'h_avg_abs_gd', \n",
    "    'v_avg_abs_gs', \n",
    "    'v_avg_abs_gd', \n",
    "    'h_avg_abs_win',\n",
    "    'h_avg_abs_draw', 'h_avg_abs_lose', 'v_avg_abs_win',\n",
    "    'v_avg_abs_draw', 'v_avg_abs_lose',\n",
    "    \n",
    "    'h_0_1_gd', \n",
    "    'h_0_1_gs', \n",
    "    'h_0_gd', \n",
    "    'h_0_gs', \n",
    "    'h_1_gd', \n",
    "    'h_1_gs',\n",
    "    'h_2_3_gd', \n",
    "    'h_2_3_gs', \n",
    "    'h_2_gd', 'h_2_gs', 'h_3_gd', 'h_3_gs',\n",
    "    'h_4_gd', 'h_4_gs', 'h_5_gd', 'h_5_gs', 'h_6_gd', 'h_6_gs',\n",
    "    'h_7_gd', 'h_7_gs', 'h_ab_4_gd', 'h_ab_4_gs', 'h_abs_avg_g',\n",
    "    'h_abs_avg_gd', 'h_abs_avg_gs', 'h_abs_draw', 'h_abs_g',\n",
    "    'h_abs_gd', 'h_abs_gs', 'h_abs_lose', 'h_abs_win', 'h_count',\n",
    "    'h_host_count', \n",
    "    'h_host_draw', \n",
    "    'h_host_g', 'h_host_gd',\n",
    "    'h_host_gs', \n",
    "    'h_host_lose', 'h_host_win', \n",
    "    \n",
    "    'v_0_1_gd',\n",
    "    'v_0_1_gs', 'v_0_gd', 'v_0_gs', 'v_1_gd', 'v_1_gs', 'v_2_3_gd',\n",
    "    'v_2_3_gs', 'v_2_gd', 'v_2_gs', 'v_3_gd', 'v_3_gs', 'v_4_gd',\n",
    "    'v_4_gs', 'v_5_gd', 'v_5_gs', 'v_6_gd', 'v_6_gs', 'v_7_gd',\n",
    "    'v_7_gs', 'v_ab_4_gd', 'v_ab_4_gs', 'v_abs_avg_g', 'v_abs_avg_gd',\n",
    "    'v_abs_avg_gs', 'v_abs_draw', 'v_abs_g', 'v_abs_gd', 'v_abs_gs',\n",
    "    'v_abs_lose', 'v_abs_win', \n",
    "    \n",
    "    'v_count', \n",
    "    'v_visit_count',\n",
    "    'v_visit_draw', \n",
    "    'v_visit_g', 'v_visit_gd', 'v_visit_gs',\n",
    "    'v_visit_lose', 'v_visit_win',\n",
    "    \n",
    "    'h_0_1_gd_rate', 'h_0_1_gs_rate',\n",
    "    'h_0_gd_rate', 'h_0_gs_rate', 'h_1_gd_rate', 'h_1_gs_rate',\n",
    "    'h_2_3_gd_rate', 'h_2_3_gs_rate', 'h_2_gd_rate', 'h_2_gs_rate',\n",
    "    'h_3_gd_rate', 'h_3_gs_rate', 'h_4_gd_rate', 'h_4_gs_rate',\n",
    "    'h_5_gd_rate', 'h_5_gs_rate', 'h_6_gd_rate', 'h_6_gs_rate',\n",
    "    'h_7_gd_rate', 'h_7_gs_rate', 'h_ab_4_gd_rate', 'h_ab_4_gs_rate',\n",
    "    'h_abs_draw_rate', 'h_abs_lose_rate', 'h_abs_win_rate',\n",
    "    'v_0_1_gd_rate', 'v_0_1_gs_rate', 'v_0_gd_rate', 'v_0_gs_rate',\n",
    "    'v_1_gd_rate', 'v_1_gs_rate', 'v_2_3_gd_rate', 'v_2_3_gs_rate',\n",
    "    'v_2_gd_rate', 'v_2_gs_rate', 'v_3_gd_rate', 'v_3_gs_rate',\n",
    "    'v_4_gd_rate', 'v_4_gs_rate', 'v_5_gd_rate', 'v_5_gs_rate',\n",
    "    'v_6_gd_rate', 'v_6_gs_rate', 'v_7_gd_rate', 'v_7_gs_rate',\n",
    "    \n",
    "    'v_ab_4_gd_rate', \n",
    "    'v_ab_4_gs_rate', \n",
    "    'v_abs_draw_rate',\n",
    "    'v_abs_lose_rate', \n",
    "    'v_abs_win_rate',\n",
    "    'h_host_draw_rate',\n",
    "    'h_host_g_rate', \n",
    "    'h_host_gd_rate', \n",
    "    'h_host_gs_rate',\n",
    "    'h_host_lose_rate', \n",
    "    'h_host_win_rate', \n",
    "    'v_visit_draw_rate',\n",
    "    'v_visit_g_rate', \n",
    "    'v_visit_gd_rate', \n",
    "    'v_visit_gs_rate',\n",
    "    'v_visit_lose_rate', \n",
    "    'v_visit_win_rate',\n",
    "    \n",
    "    'avg_init_draw_odd',\n",
    "    'avg_init_lose_odd', 'avg_init_win_odd', 'avg_new_draw_kelly',\n",
    "    'avg_new_draw_odd', 'avg_new_draw_rate', 'avg_new_lose_kelly',\n",
    "    'avg_new_lose_odd', 'avg_new_lose_rate', 'avg_new_win_kelly',\n",
    "    'avg_new_win_odd', 'avg_new_win_rate', 'avg_pay_rate',\n",
    "    'dispersion_draw', 'dispersion_lose', 'dispersion_win', \n",
    "    'max_init_draw_odd', 'max_init_lose_odd', 'max_init_win_odd',\n",
    "    'max_new_draw_kelly', 'max_new_draw_odd', 'max_new_draw_rate',\n",
    "    'max_new_lose_kelly', 'max_new_lose_odd', 'max_new_lose_rate',\n",
    "    'max_new_win_kelly', 'max_new_win_odd', 'max_new_win_rate',\n",
    "    'max_pay_rate', 'min_init_draw_odd', 'min_init_lose_odd',\n",
    "    'min_init_win_odd', 'min_new_draw_kelly', 'min_new_draw_odd',\n",
    "    'min_new_draw_rate', 'min_new_lose_kelly', 'min_new_lose_odd',\n",
    "    'min_new_lose_rate', 'min_new_win_kelly', 'min_new_win_odd',\n",
    "    'min_new_win_rate', 'min_pay_rate', 'std_draw', 'std_lose',\n",
    "    'std_win'\n",
    "]\n",
    "    \n",
    "params={\n",
    "    'booster':'gbtree',\n",
    "    # 这里手写数字是0-9，是一个多类的问题，因此采用了multisoft多分类器，\n",
    "    'objective': 'reg:linear', \n",
    "#     'objective': 'multi:softprob',\n",
    "#     'num_class':3, # 类数，与 multisoftmax 并用\n",
    "    \n",
    "    'gamma':0.01,  # 在树的叶子节点下一个分区的最小损失，越大算法模型越保守 。[0:]\n",
    "    'max_depth':8, # 构建树的深度 [1:]\n",
    "    \n",
    "    #'lambda':450,  # L2 正则项权重\n",
    "    'subsample':0.7, # 采样训练数据，设置为0.5，随机选择一般的数据实例 (0:1]\n",
    "    'colsample_bytree':0.7, # 构建树树时的采样比率 (0:1]\n",
    "    #'min_child_weight':12, # 节点的最少特征数\n",
    "    'silent':1 ,\n",
    "    \n",
    "#     这部分需要调整\n",
    "#     'eta': 0.05, # 如同学习率\n",
    "    'eta': 0.01, # 如同学习率\n",
    "    \n",
    "    \n",
    "    'seed':2018,\n",
    "    'nthread':4,# cpu 线程数,根据自己U的个数适当调整\n",
    "}\n",
    "\n",
    "t = train_dataset_df\n",
    "\n",
    "train_dataset = t[t['year'] < 2019]\n",
    "test_dataset = t[t['year'] == 2019]\n",
    "\n",
    "valid_dataset = test_dataset[test_dataset['month'] < 3]\n",
    "test_dataset = test_dataset[test_dataset['month'] >= 3]\n",
    "\n",
    "xgtrain = xgb.DMatrix(train_dataset[x_columns], label=train_dataset['fix_result'])\n",
    "xgtest = xgb.DMatrix(test_dataset[x_columns], label=test_dataset['fix_result'])\n",
    "xgvalid = xgb.DMatrix(valid_dataset[x_columns], label=valid_dataset['fix_result'])\n",
    "\n",
    "watchlist = [(xgtrain, 'train'),(xgvalid, 'val')]\n",
    "\n",
    "num_rounds = 10000\n",
    "stop_rounds = 100\n",
    "\n",
    "# num_rounds = 10000\n",
    "# stop_rounds = 300\n",
    "\n",
    "model = xgb.train(params, xgtrain, num_rounds, watchlist, early_stopping_rounds=stop_rounds)\n",
    "print(model.best_iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.12780607,  0.06444144,  0.9051274 , ...,  1.1600151 ,\n",
       "        0.85846794, -0.58223426], dtype=float32)"
      ]
     },
     "execution_count": 393,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = model.predict(xgtest, ntree_limit=model.best_iteration)\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset['preds'] = preds\n",
    "# test_dataset[['gs', 'gd', 'fix_result', 'preds']].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def get_score(row):\n",
    "    if row.preds > 0:\n",
    "        return -(math.floor(row.preds)) \n",
    "#         return -(math.floor(row.preds)) + 0.5\n",
    "    else:\n",
    "        return -(math.ceil(row.preds))\n",
    "#         return -(math.ceil(row.preds)) - 0.5\n",
    "\n",
    "# test_dataset['rq'] = test_dataset.apply(lambda row: math.floor(math.floor(row.preds * 10) / 5) * 0.5, axis=1)\n",
    "# test_dataset['rq'] = test_dataset.apply(lambda row: get_score(row), axis=1)\n",
    "\n",
    "test_dataset['rq'] = -test_dataset['preds']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset['rq_result'] = test_dataset['rq'] + test_dataset['fix_result']\n",
    "test_dataset['pred_rq_result'] = test_dataset.apply(lambda row: 1 if row.rq_result > 0 else 0, axis=1)\n",
    "\n",
    "# a = test_dataset[test_dataset['rq'] >= 0]\n",
    "# a = test_dataset\n",
    "# print(len(a[a['pred_rq_result'] == 1])/ len(a))\n",
    "# a[['matchid', 'gs', 'gd', 'fix_result', 'rq', 'rq_result', 'pred_rq_result']].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(796, 1131)"
      ]
     },
     "execution_count": 456,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.merge(test_dataset, train_game_offset_df, on='matchid', how='left')\n",
    "test_df = test_df.dropna()\n",
    "len(test_df), len(test_dataset)\n",
    "# test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['offset_result'] = test_df.apply(lambda row: 1 if (row.fix_result + row.new_offset_val) > 0 else 0, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['pred_offset_result'] = test_df.apply(lambda row: 1 if (row.new_offset_val - row.rq) > 0 else 0, axis=1)\n",
    "test_df['gap'] = test_df['new_offset_val'] - test_df['rq']\n",
    "# test_df['pred_offset_result'] = test_df.apply(lambda row: 1 if (row.offset_result - row.rq) > 0 else 0, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6212121212121212"
      ]
     },
     "execution_count": 477,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['check'] = test_df.apply(lambda row: 1 if row.offset_result == row.pred_offset_result else 0, axis=1)\n",
    "# len(test_df[(test_df['check'] == 1) & (test_df['rq'] < 0)]) / len(test_df[test_df['rq'] < 0])\n",
    "\n",
    "len(test_df[(test_df['check'] == 1)  & (test_df['gap']<-0.2) ])/len(test_df[test_df['gap'] < -0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_df['rq'].drop_duplicates().values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>matchid</th>\n",
       "      <th>gs</th>\n",
       "      <th>gd</th>\n",
       "      <th>fix_result</th>\n",
       "      <th>rq</th>\n",
       "      <th>new_offset_val</th>\n",
       "      <th>offset_result</th>\n",
       "      <th>pred_offset_result</th>\n",
       "      <th>check</th>\n",
       "      <th>gap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>2413915</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.035815</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.214185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>2411061</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.029904</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.279904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>2514207</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-0.260396</td>\n",
       "      <td>-0.50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.239604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>2406860</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.215090</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.215090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>2405428</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-1.614174</td>\n",
       "      <td>-2.50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.885826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>2406877</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>-3</td>\n",
       "      <td>-0.867995</td>\n",
       "      <td>-1.25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.382005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>2514294</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.244505</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.244505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>2405498</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>-1.788952</td>\n",
       "      <td>-2.50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.711048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>2405479</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>-2.442473</td>\n",
       "      <td>-2.75</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.307527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>2514337</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>-3</td>\n",
       "      <td>-0.285710</td>\n",
       "      <td>-0.50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.214290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>2514334</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.568759</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.318759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>2406371</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.787785</td>\n",
       "      <td>-2.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.212215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>2411083</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>-2</td>\n",
       "      <td>0.570518</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.320518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>2406881</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>-3</td>\n",
       "      <td>0.631740</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.381740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>2405503</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.501605</td>\n",
       "      <td>-1.75</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.248395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>2514312</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.086847</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.336847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>2514313</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.230039</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.230039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>2514374</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.098109</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.348109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>2402896</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.854985</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.354985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>2514387</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.986539</td>\n",
       "      <td>-1.25</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.263461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>2411776</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>-2</td>\n",
       "      <td>0.237801</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.237801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>2436078</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>-1.715122</td>\n",
       "      <td>-2.25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.534878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418</th>\n",
       "      <td>2514405</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>-2</td>\n",
       "      <td>0.766584</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.266584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>434</th>\n",
       "      <td>2411829</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.971193</td>\n",
       "      <td>-1.25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.278807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445</th>\n",
       "      <td>2508586</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.049844</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.200156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>2406441</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.557834</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.307834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>2437959</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.582520</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.332520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>545</th>\n",
       "      <td>2402923</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.545418</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.295418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>546</th>\n",
       "      <td>2437961</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.226483</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.226483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557</th>\n",
       "      <td>2508599</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.247902</td>\n",
       "      <td>-1.50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.252098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>655</th>\n",
       "      <td>2411144</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.309097</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.309097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>667</th>\n",
       "      <td>2405485</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.711611</td>\n",
       "      <td>-2.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.288389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>678</th>\n",
       "      <td>2508637</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.703048</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.296952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>683</th>\n",
       "      <td>2514496</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.535088</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.285088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>699</th>\n",
       "      <td>2502893</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.187312</td>\n",
       "      <td>-1.50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.312688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>740</th>\n",
       "      <td>2502930</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.240473</td>\n",
       "      <td>-1.50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.259527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>826</th>\n",
       "      <td>2502927</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>-1.203697</td>\n",
       "      <td>-1.50</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.296303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>836</th>\n",
       "      <td>2406473</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.288709</td>\n",
       "      <td>-2.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.711291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>838</th>\n",
       "      <td>2406517</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.483016</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.233016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>862</th>\n",
       "      <td>2429010</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>-2.021304</td>\n",
       "      <td>-2.25</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.228696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>2411880</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.226137</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.226137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>892</th>\n",
       "      <td>2437477</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>-2</td>\n",
       "      <td>1.461991</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.461991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>902</th>\n",
       "      <td>2415173</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.198128</td>\n",
       "      <td>-1.50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.301872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>917</th>\n",
       "      <td>2405607</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>-2.723546</td>\n",
       "      <td>-3.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.276454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>918</th>\n",
       "      <td>2428975</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2.099128</td>\n",
       "      <td>1.75</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.349128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>951</th>\n",
       "      <td>2508699</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.589831</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.410169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>969</th>\n",
       "      <td>2514610</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>-2</td>\n",
       "      <td>0.492764</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.242764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>971</th>\n",
       "      <td>2437470</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>-1.089791</td>\n",
       "      <td>-1.50</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.410209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>973</th>\n",
       "      <td>2405612</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.265644</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.265644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>992</th>\n",
       "      <td>2503930</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.138923</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.388923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>2428971</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>-3</td>\n",
       "      <td>1.069836</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.569836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1020</th>\n",
       "      <td>2402946</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.786620</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.286620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1050</th>\n",
       "      <td>2514623</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.222114</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.222114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1061</th>\n",
       "      <td>2413996</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>-2.857353</td>\n",
       "      <td>-3.75</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.892647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1062</th>\n",
       "      <td>2411853</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.613939</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.363939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1070</th>\n",
       "      <td>2429039</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>-2.322973</td>\n",
       "      <td>-2.75</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.427027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1081</th>\n",
       "      <td>2514643</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>-2</td>\n",
       "      <td>-0.290638</td>\n",
       "      <td>-0.50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.209362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1095</th>\n",
       "      <td>2411200</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.213886</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.213886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1113</th>\n",
       "      <td>2429046</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>-2</td>\n",
       "      <td>-0.680320</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.319680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1116</th>\n",
       "      <td>2502974</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.827573</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.327573</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>66 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      matchid  gs  gd  fix_result        rq  new_offset_val  offset_result  \\\n",
       "39    2413915   3   2           1 -0.035815           -0.25              1   \n",
       "47    2411061   3   2           1  0.029904           -0.25              1   \n",
       "74    2514207   0   2          -2 -0.260396           -0.50              0   \n",
       "89    2406860   2   0           2  0.215090            0.00              1   \n",
       "94    2405428   4   2           2 -1.614174           -2.50              0   \n",
       "121   2406877   2   5          -3 -0.867995           -1.25              0   \n",
       "137   2514294   2   1           1  0.244505            0.00              1   \n",
       "160   2405498   3   1           2 -1.788952           -2.50              0   \n",
       "163   2405479   2   0           2 -2.442473           -2.75              0   \n",
       "175   2514337   2   5          -3 -0.285710           -0.50              0   \n",
       "176   2514334   0   1          -1  0.568759            0.25              0   \n",
       "208   2406371   1   1           0 -1.787785           -2.00              0   \n",
       "216   2411083   0   2          -2  0.570518            0.25              0   \n",
       "229   2406881   0   3          -3  0.631740            0.25              0   \n",
       "272   2405503   2   3          -1 -1.501605           -1.75              0   \n",
       "286   2514312   2   1           1  0.086847           -0.25              1   \n",
       "290   2514313   1   0           1  0.230039            0.00              1   \n",
       "338   2514374   0   1          -1  0.098109           -0.25              0   \n",
       "362   2402896   0   1          -1  0.854985            0.50              0   \n",
       "375   2514387   2   0           2 -0.986539           -1.25              1   \n",
       "384   2411776   1   3          -2  0.237801            0.00              0   \n",
       "399   2436078   2   0           2 -1.715122           -2.25              0   \n",
       "418   2514405   0   2          -2  0.766584            0.50              0   \n",
       "434   2411829   2   2           0 -0.971193           -1.25              0   \n",
       "445   2508586   1   2          -1 -0.049844           -0.25              0   \n",
       "452   2406441   4   1           3  0.557834            0.25              1   \n",
       "513   2437959   0   0           0  0.582520            0.25              1   \n",
       "545   2402923   1   1           0  0.545418            0.25              1   \n",
       "546   2437961   0   1          -1  0.226483            0.00              0   \n",
       "557   2508599   1   0           1 -1.247902           -1.50              0   \n",
       "...       ...  ..  ..         ...       ...             ...            ...   \n",
       "655   2411144   4   0           4  0.309097            0.00              1   \n",
       "667   2405485   2   3          -1 -1.711611           -2.00              0   \n",
       "678   2508637   2   1           1 -0.703048           -1.00              0   \n",
       "683   2514496   2   1           1  0.535088            0.25              1   \n",
       "699   2502893   2   1           1 -1.187312           -1.50              0   \n",
       "740   2502930   4   3           1 -1.240473           -1.50              0   \n",
       "826   2502927   3   1           2 -1.203697           -1.50              1   \n",
       "836   2406473   0   0           0 -1.288709           -2.00              0   \n",
       "838   2406517   1   0           1  0.483016            0.25              1   \n",
       "862   2429010   6   0           6 -2.021304           -2.25              1   \n",
       "889   2411880   1   2          -1  0.226137            0.00              0   \n",
       "892   2437477   3   5          -2  1.461991            1.00              0   \n",
       "902   2415173   1   2          -1 -1.198128           -1.50              0   \n",
       "917   2405607   5   0           5 -2.723546           -3.00              1   \n",
       "918   2428975   2   2           0  2.099128            1.75              1   \n",
       "951   2508699   1   2          -1 -0.589831           -1.00              0   \n",
       "969   2514610   0   2          -2  0.492764            0.25              0   \n",
       "971   2437470   5   0           5 -1.089791           -1.50              1   \n",
       "973   2405612   3   0           3  0.265644            0.00              1   \n",
       "992   2503930   5   2           3  0.138923           -0.25              1   \n",
       "996   2428971   1   4          -3  1.069836            0.50              0   \n",
       "1020  2402946   3   2           1  0.786620            0.50              1   \n",
       "1050  2514623   2   1           1  1.222114            1.00              1   \n",
       "1061  2413996   3   1           2 -2.857353           -3.75              0   \n",
       "1062  2411853   1   1           0  0.613939            0.25              1   \n",
       "1070  2429039   5   1           4 -2.322973           -2.75              1   \n",
       "1081  2514643   1   3          -2 -0.290638           -0.50              0   \n",
       "1095  2411200   3   2           1  1.213886            1.00              1   \n",
       "1113  2429046   1   3          -2 -0.680320           -1.00              0   \n",
       "1116  2502974   2   3          -1  0.827573            0.50              0   \n",
       "\n",
       "      pred_offset_result  check       gap  \n",
       "39                     0      0 -0.214185  \n",
       "47                     0      0 -0.279904  \n",
       "74                     0      1 -0.239604  \n",
       "89                     0      0 -0.215090  \n",
       "94                     0      1 -0.885826  \n",
       "121                    0      1 -0.382005  \n",
       "137                    0      0 -0.244505  \n",
       "160                    0      1 -0.711048  \n",
       "163                    0      1 -0.307527  \n",
       "175                    0      1 -0.214290  \n",
       "176                    0      1 -0.318759  \n",
       "208                    0      1 -0.212215  \n",
       "216                    0      1 -0.320518  \n",
       "229                    0      1 -0.381740  \n",
       "272                    0      1 -0.248395  \n",
       "286                    0      0 -0.336847  \n",
       "290                    0      0 -0.230039  \n",
       "338                    0      1 -0.348109  \n",
       "362                    0      1 -0.354985  \n",
       "375                    0      0 -0.263461  \n",
       "384                    0      1 -0.237801  \n",
       "399                    0      1 -0.534878  \n",
       "418                    0      1 -0.266584  \n",
       "434                    0      1 -0.278807  \n",
       "445                    0      1 -0.200156  \n",
       "452                    0      0 -0.307834  \n",
       "513                    0      0 -0.332520  \n",
       "545                    0      0 -0.295418  \n",
       "546                    0      1 -0.226483  \n",
       "557                    0      1 -0.252098  \n",
       "...                  ...    ...       ...  \n",
       "655                    0      0 -0.309097  \n",
       "667                    0      1 -0.288389  \n",
       "678                    0      1 -0.296952  \n",
       "683                    0      0 -0.285088  \n",
       "699                    0      1 -0.312688  \n",
       "740                    0      1 -0.259527  \n",
       "826                    0      0 -0.296303  \n",
       "836                    0      1 -0.711291  \n",
       "838                    0      0 -0.233016  \n",
       "862                    0      0 -0.228696  \n",
       "889                    0      1 -0.226137  \n",
       "892                    0      1 -0.461991  \n",
       "902                    0      1 -0.301872  \n",
       "917                    0      0 -0.276454  \n",
       "918                    0      0 -0.349128  \n",
       "951                    0      1 -0.410169  \n",
       "969                    0      1 -0.242764  \n",
       "971                    0      0 -0.410209  \n",
       "973                    0      0 -0.265644  \n",
       "992                    0      0 -0.388923  \n",
       "996                    0      1 -0.569836  \n",
       "1020                   0      0 -0.286620  \n",
       "1050                   0      0 -0.222114  \n",
       "1061                   0      1 -0.892647  \n",
       "1062                   0      0 -0.363939  \n",
       "1070                   0      0 -0.427027  \n",
       "1081                   0      1 -0.209362  \n",
       "1095                   0      0 -0.213886  \n",
       "1113                   0      1 -0.319680  \n",
       "1116                   0      1 -0.327573  \n",
       "\n",
       "[66 rows x 10 columns]"
      ]
     },
     "execution_count": 479,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df[test_df['gap']< -0.2][['matchid', 'gs', 'gd', 'fix_result', 'rq', 'new_offset_val', 'offset_result', 'pred_offset_result', 'check', 'gap']]\n",
    "# test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## xgb训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30980\n",
      "[0]\ttrain-merror:0.46384\tval-merror:0.536404\n",
      "Multiple eval metrics have been passed: 'val-merror' will be used for early stopping.\n",
      "\n",
      "Will train until val-merror hasn't improved in 100 rounds.\n",
      "[1]\ttrain-merror:0.45606\tval-merror:0.536404\n",
      "[2]\ttrain-merror:0.453146\tval-merror:0.534918\n",
      "[3]\ttrain-merror:0.453695\tval-merror:0.533432\n",
      "[4]\ttrain-merror:0.453935\tval-merror:0.523031\n",
      "[5]\ttrain-merror:0.455066\tval-merror:0.526003\n",
      "[6]\ttrain-merror:0.454209\tval-merror:0.534918\n",
      "[7]\ttrain-merror:0.452667\tval-merror:0.531946\n",
      "[8]\ttrain-merror:0.450747\tval-merror:0.523031\n",
      "[9]\ttrain-merror:0.45061\tval-merror:0.524517\n",
      "[10]\ttrain-merror:0.450644\tval-merror:0.524517\n",
      "[11]\ttrain-merror:0.450781\tval-merror:0.527489\n",
      "[12]\ttrain-merror:0.450713\tval-merror:0.530461\n",
      "[13]\ttrain-merror:0.451056\tval-merror:0.530461\n",
      "[14]\ttrain-merror:0.450233\tval-merror:0.527489\n",
      "[15]\ttrain-merror:0.449925\tval-merror:0.524517\n",
      "[16]\ttrain-merror:0.45037\tval-merror:0.526003\n",
      "[17]\ttrain-merror:0.449685\tval-merror:0.527489\n",
      "[18]\ttrain-merror:0.450473\tval-merror:0.528975\n",
      "[19]\ttrain-merror:0.450404\tval-merror:0.527489\n",
      "[20]\ttrain-merror:0.450644\tval-merror:0.524517\n",
      "[21]\ttrain-merror:0.450233\tval-merror:0.528975\n",
      "[22]\ttrain-merror:0.44989\tval-merror:0.527489\n",
      "[23]\ttrain-merror:0.449445\tval-merror:0.524517\n",
      "[24]\ttrain-merror:0.448725\tval-merror:0.520059\n",
      "[25]\ttrain-merror:0.448896\tval-merror:0.518574\n",
      "[26]\ttrain-merror:0.449513\tval-merror:0.524517\n",
      "[27]\ttrain-merror:0.44989\tval-merror:0.521545\n",
      "[28]\ttrain-merror:0.450199\tval-merror:0.524517\n",
      "[29]\ttrain-merror:0.450576\tval-merror:0.520059\n",
      "[30]\ttrain-merror:0.450884\tval-merror:0.523031\n",
      "[31]\ttrain-merror:0.450919\tval-merror:0.521545\n",
      "[32]\ttrain-merror:0.45109\tval-merror:0.521545\n",
      "[33]\ttrain-merror:0.450679\tval-merror:0.523031\n",
      "[34]\ttrain-merror:0.450439\tval-merror:0.526003\n",
      "[35]\ttrain-merror:0.450884\tval-merror:0.527489\n",
      "[36]\ttrain-merror:0.450953\tval-merror:0.523031\n",
      "[37]\ttrain-merror:0.451501\tval-merror:0.523031\n",
      "[38]\ttrain-merror:0.450713\tval-merror:0.527489\n",
      "[39]\ttrain-merror:0.450302\tval-merror:0.526003\n",
      "[40]\ttrain-merror:0.450096\tval-merror:0.521545\n",
      "[41]\ttrain-merror:0.450062\tval-merror:0.523031\n",
      "[42]\ttrain-merror:0.449445\tval-merror:0.523031\n",
      "[43]\ttrain-merror:0.44965\tval-merror:0.523031\n",
      "[44]\ttrain-merror:0.450027\tval-merror:0.526003\n",
      "[45]\ttrain-merror:0.450096\tval-merror:0.520059\n",
      "[46]\ttrain-merror:0.449993\tval-merror:0.526003\n",
      "[47]\ttrain-merror:0.449959\tval-merror:0.527489\n",
      "[48]\ttrain-merror:0.449959\tval-merror:0.518574\n",
      "[49]\ttrain-merror:0.450439\tval-merror:0.523031\n",
      "[50]\ttrain-merror:0.450336\tval-merror:0.518574\n",
      "[51]\ttrain-merror:0.450302\tval-merror:0.520059\n",
      "[52]\ttrain-merror:0.450404\tval-merror:0.520059\n",
      "[53]\ttrain-merror:0.450267\tval-merror:0.520059\n",
      "[54]\ttrain-merror:0.449993\tval-merror:0.521545\n",
      "[55]\ttrain-merror:0.450062\tval-merror:0.524517\n",
      "[56]\ttrain-merror:0.449719\tval-merror:0.520059\n",
      "[57]\ttrain-merror:0.449273\tval-merror:0.518574\n",
      "[58]\ttrain-merror:0.448965\tval-merror:0.517088\n",
      "[59]\ttrain-merror:0.448862\tval-merror:0.514116\n",
      "[60]\ttrain-merror:0.448999\tval-merror:0.514116\n",
      "[61]\ttrain-merror:0.448588\tval-merror:0.515602\n",
      "[62]\ttrain-merror:0.448554\tval-merror:0.514116\n",
      "[63]\ttrain-merror:0.448279\tval-merror:0.514116\n",
      "[64]\ttrain-merror:0.448348\tval-merror:0.515602\n",
      "[65]\ttrain-merror:0.448177\tval-merror:0.51263\n",
      "[66]\ttrain-merror:0.448245\tval-merror:0.511144\n",
      "[67]\ttrain-merror:0.448108\tval-merror:0.509658\n",
      "[68]\ttrain-merror:0.448142\tval-merror:0.511144\n",
      "[69]\ttrain-merror:0.448382\tval-merror:0.511144\n",
      "[70]\ttrain-merror:0.447902\tval-merror:0.511144\n",
      "[71]\ttrain-merror:0.447765\tval-merror:0.51263\n",
      "[72]\ttrain-merror:0.447697\tval-merror:0.511144\n",
      "[73]\ttrain-merror:0.447491\tval-merror:0.511144\n",
      "[74]\ttrain-merror:0.447423\tval-merror:0.511144\n",
      "[75]\ttrain-merror:0.447011\tval-merror:0.514116\n",
      "[76]\ttrain-merror:0.446566\tval-merror:0.514116\n",
      "[77]\ttrain-merror:0.446531\tval-merror:0.517088\n",
      "[78]\ttrain-merror:0.446463\tval-merror:0.515602\n",
      "[79]\ttrain-merror:0.446908\tval-merror:0.514116\n",
      "[80]\ttrain-merror:0.446497\tval-merror:0.514116\n",
      "[81]\ttrain-merror:0.446634\tval-merror:0.514116\n",
      "[82]\ttrain-merror:0.44636\tval-merror:0.514116\n",
      "[83]\ttrain-merror:0.445983\tval-merror:0.51263\n",
      "[84]\ttrain-merror:0.445983\tval-merror:0.511144\n",
      "[85]\ttrain-merror:0.445606\tval-merror:0.511144\n",
      "[86]\ttrain-merror:0.445503\tval-merror:0.517088\n",
      "[87]\ttrain-merror:0.445263\tval-merror:0.515602\n",
      "[88]\ttrain-merror:0.445332\tval-merror:0.517088\n",
      "[89]\ttrain-merror:0.44516\tval-merror:0.517088\n",
      "[90]\ttrain-merror:0.445023\tval-merror:0.517088\n",
      "[91]\ttrain-merror:0.445058\tval-merror:0.517088\n",
      "[92]\ttrain-merror:0.445126\tval-merror:0.515602\n",
      "[93]\ttrain-merror:0.44516\tval-merror:0.515602\n",
      "[94]\ttrain-merror:0.445332\tval-merror:0.517088\n",
      "[95]\ttrain-merror:0.445366\tval-merror:0.520059\n",
      "[96]\ttrain-merror:0.444955\tval-merror:0.521545\n",
      "[97]\ttrain-merror:0.444475\tval-merror:0.515602\n",
      "[98]\ttrain-merror:0.444372\tval-merror:0.517088\n",
      "[99]\ttrain-merror:0.444132\tval-merror:0.518574\n",
      "[100]\ttrain-merror:0.444304\tval-merror:0.518574\n",
      "[101]\ttrain-merror:0.444064\tval-merror:0.518574\n",
      "[102]\ttrain-merror:0.443961\tval-merror:0.517088\n",
      "[103]\ttrain-merror:0.443687\tval-merror:0.514116\n",
      "[104]\ttrain-merror:0.443378\tval-merror:0.511144\n",
      "[105]\ttrain-merror:0.443447\tval-merror:0.51263\n",
      "[106]\ttrain-merror:0.443481\tval-merror:0.509658\n",
      "[107]\ttrain-merror:0.443721\tval-merror:0.51263\n",
      "[108]\ttrain-merror:0.443755\tval-merror:0.514116\n",
      "[109]\ttrain-merror:0.443858\tval-merror:0.51263\n",
      "[110]\ttrain-merror:0.44331\tval-merror:0.51263\n",
      "[111]\ttrain-merror:0.443378\tval-merror:0.51263\n",
      "[112]\ttrain-merror:0.443481\tval-merror:0.515602\n",
      "[113]\ttrain-merror:0.443549\tval-merror:0.517088\n",
      "[114]\ttrain-merror:0.443378\tval-merror:0.515602\n",
      "[115]\ttrain-merror:0.443447\tval-merror:0.515602\n",
      "[116]\ttrain-merror:0.443104\tval-merror:0.515602\n",
      "[117]\ttrain-merror:0.442864\tval-merror:0.515602\n",
      "[118]\ttrain-merror:0.442898\tval-merror:0.517088\n",
      "[119]\ttrain-merror:0.443001\tval-merror:0.51263\n",
      "[120]\ttrain-merror:0.442933\tval-merror:0.514116\n",
      "[121]\ttrain-merror:0.442693\tval-merror:0.517088\n",
      "[122]\ttrain-merror:0.442418\tval-merror:0.520059\n",
      "[123]\ttrain-merror:0.442179\tval-merror:0.517088\n",
      "[124]\ttrain-merror:0.442418\tval-merror:0.517088\n",
      "[125]\ttrain-merror:0.442247\tval-merror:0.518574\n",
      "[126]\ttrain-merror:0.442076\tval-merror:0.520059\n",
      "[127]\ttrain-merror:0.442213\tval-merror:0.518574\n",
      "[128]\ttrain-merror:0.442281\tval-merror:0.518574\n",
      "[129]\ttrain-merror:0.442179\tval-merror:0.515602\n",
      "[130]\ttrain-merror:0.442076\tval-merror:0.517088\n",
      "[131]\ttrain-merror:0.441939\tval-merror:0.515602\n",
      "[132]\ttrain-merror:0.442007\tval-merror:0.515602\n",
      "[133]\ttrain-merror:0.442041\tval-merror:0.515602\n",
      "[134]\ttrain-merror:0.441973\tval-merror:0.515602\n",
      "[135]\ttrain-merror:0.441973\tval-merror:0.515602\n",
      "[136]\ttrain-merror:0.441801\tval-merror:0.515602\n",
      "[137]\ttrain-merror:0.441904\tval-merror:0.514116\n",
      "[138]\ttrain-merror:0.441287\tval-merror:0.514116\n",
      "[139]\ttrain-merror:0.441013\tval-merror:0.517088\n",
      "[140]\ttrain-merror:0.441013\tval-merror:0.517088\n",
      "[141]\ttrain-merror:0.441047\tval-merror:0.517088\n",
      "[142]\ttrain-merror:0.440808\tval-merror:0.515602\n",
      "[143]\ttrain-merror:0.440636\tval-merror:0.515602\n",
      "[144]\ttrain-merror:0.440568\tval-merror:0.515602\n",
      "[145]\ttrain-merror:0.440465\tval-merror:0.515602\n",
      "[146]\ttrain-merror:0.440773\tval-merror:0.515602\n",
      "[147]\ttrain-merror:0.440602\tval-merror:0.515602\n",
      "[148]\ttrain-merror:0.440191\tval-merror:0.517088\n",
      "[149]\ttrain-merror:0.440259\tval-merror:0.517088\n",
      "[150]\ttrain-merror:0.439985\tval-merror:0.518574\n",
      "[151]\ttrain-merror:0.439848\tval-merror:0.518574\n",
      "[152]\ttrain-merror:0.439471\tval-merror:0.518574\n",
      "[153]\ttrain-merror:0.439231\tval-merror:0.518574\n",
      "[154]\ttrain-merror:0.439437\tval-merror:0.518574\n",
      "[155]\ttrain-merror:0.439505\tval-merror:0.518574\n",
      "[156]\ttrain-merror:0.439402\tval-merror:0.518574\n",
      "[157]\ttrain-merror:0.439368\tval-merror:0.517088\n",
      "[158]\ttrain-merror:0.439059\tval-merror:0.518574\n",
      "[159]\ttrain-merror:0.439059\tval-merror:0.517088\n",
      "[160]\ttrain-merror:0.438648\tval-merror:0.518574\n",
      "[161]\ttrain-merror:0.438648\tval-merror:0.520059\n",
      "[162]\ttrain-merror:0.438511\tval-merror:0.518574\n",
      "[163]\ttrain-merror:0.438511\tval-merror:0.517088\n",
      "[164]\ttrain-merror:0.438477\tval-merror:0.518574\n",
      "[165]\ttrain-merror:0.438614\tval-merror:0.515602\n",
      "[166]\ttrain-merror:0.438511\tval-merror:0.515602\n",
      "[167]\ttrain-merror:0.438682\tval-merror:0.517088\n",
      "Stopping. Best iteration:\n",
      "[67]\ttrain-merror:0.448108\tval-merror:0.509658\n",
      "\n",
      "67\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "x_columns = [\n",
    "#     'win_bet_return', 'draw_bet_return', 'lose_bet_return', \n",
    "#     'year', 'month',\n",
    "#     'home_team_encoder', 'visit_team_encoder', 'game_encoder',\n",
    "    \n",
    "#     'h_avg_abs_gs',\n",
    "#     'h_avg_abs_gd', 'v_avg_abs_gs', 'v_avg_abs_gd', 'h_avg_abs_win',\n",
    "#     'h_avg_abs_draw', 'h_avg_abs_lose', 'v_avg_abs_win',\n",
    "#     'v_avg_abs_draw', 'v_avg_abs_lose',\n",
    "    \n",
    "#     'h_0_1_gd', \n",
    "#     'h_0_1_gs', \n",
    "#     'h_0_gd', \n",
    "#     'h_0_gs', \n",
    "#     'h_1_gd', \n",
    "#     'h_1_gs',\n",
    "#     'h_2_3_gd', \n",
    "#     'h_2_3_gs', \n",
    "#     'h_2_gd', 'h_2_gs', 'h_3_gd', 'h_3_gs',\n",
    "#     'h_4_gd', 'h_4_gs', 'h_5_gd', 'h_5_gs', 'h_6_gd', 'h_6_gs',\n",
    "#     'h_7_gd', 'h_7_gs', 'h_ab_4_gd', 'h_ab_4_gs', 'h_abs_avg_g',\n",
    "#     'h_abs_avg_gd', 'h_abs_avg_gs', 'h_abs_draw', 'h_abs_g',\n",
    "#     'h_abs_gd', 'h_abs_gs', 'h_abs_lose', 'h_abs_win', 'h_count',\n",
    "#     'h_host_count', 'h_host_draw', 'h_host_g', 'h_host_gd',\n",
    "#     'h_host_gs', 'h_host_lose', 'h_host_win', \n",
    "    \n",
    "#     'v_0_1_gd',\n",
    "#     'v_0_1_gs', 'v_0_gd', 'v_0_gs', 'v_1_gd', 'v_1_gs', 'v_2_3_gd',\n",
    "#     'v_2_3_gs', 'v_2_gd', 'v_2_gs', 'v_3_gd', 'v_3_gs', 'v_4_gd',\n",
    "#     'v_4_gs', 'v_5_gd', 'v_5_gs', 'v_6_gd', 'v_6_gs', 'v_7_gd',\n",
    "#     'v_7_gs', 'v_ab_4_gd', 'v_ab_4_gs', 'v_abs_avg_g', 'v_abs_avg_gd',\n",
    "#     'v_abs_avg_gs', 'v_abs_draw', 'v_abs_g', 'v_abs_gd', 'v_abs_gs',\n",
    "#     'v_abs_lose', 'v_abs_win', \n",
    "    \n",
    "#     'v_count', \n",
    "#     'v_visit_count',\n",
    "#     'v_visit_draw', 'v_visit_g', 'v_visit_gd', 'v_visit_gs',\n",
    "#     'v_visit_lose', 'v_visit_win',\n",
    "    \n",
    "#     'h_0_1_gd_rate', 'h_0_1_gs_rate',\n",
    "#     'h_0_gd_rate', 'h_0_gs_rate', 'h_1_gd_rate', 'h_1_gs_rate',\n",
    "#     'h_2_3_gd_rate', 'h_2_3_gs_rate', 'h_2_gd_rate', 'h_2_gs_rate',\n",
    "#     'h_3_gd_rate', 'h_3_gs_rate', 'h_4_gd_rate', 'h_4_gs_rate',\n",
    "#     'h_5_gd_rate', 'h_5_gs_rate', 'h_6_gd_rate', 'h_6_gs_rate',\n",
    "#     'h_7_gd_rate', 'h_7_gs_rate', 'h_ab_4_gd_rate', 'h_ab_4_gs_rate',\n",
    "#     'h_abs_draw_rate', 'h_abs_lose_rate', 'h_abs_win_rate',\n",
    "#     'v_0_1_gd_rate', 'v_0_1_gs_rate', 'v_0_gd_rate', 'v_0_gs_rate',\n",
    "#     'v_1_gd_rate', 'v_1_gs_rate', 'v_2_3_gd_rate', 'v_2_3_gs_rate',\n",
    "#     'v_2_gd_rate', 'v_2_gs_rate', 'v_3_gd_rate', 'v_3_gs_rate',\n",
    "#     'v_4_gd_rate', 'v_4_gs_rate', 'v_5_gd_rate', 'v_5_gs_rate',\n",
    "#     'v_6_gd_rate', 'v_6_gs_rate', 'v_7_gd_rate', 'v_7_gs_rate',\n",
    "    \n",
    "#     'v_ab_4_gd_rate', \n",
    "#     'v_ab_4_gs_rate', \n",
    "#     'v_abs_draw_rate',\n",
    "#     'v_abs_lose_rate', \n",
    "#     'v_abs_win_rate',\n",
    "#     'h_host_draw_rate',\n",
    "#     'h_host_g_rate', \n",
    "#     'h_host_gd_rate', \n",
    "#     'h_host_gs_rate',\n",
    "#     'h_host_lose_rate', \n",
    "#     'h_host_win_rate', \n",
    "#     'v_visit_draw_rate',\n",
    "#     'v_visit_g_rate', \n",
    "#     'v_visit_gd_rate', \n",
    "#     'v_visit_gs_rate',\n",
    "#     'v_visit_lose_rate', \n",
    "#     'v_visit_win_rate',\n",
    "    \n",
    "    'avg_init_draw_odd',\n",
    "    'avg_init_lose_odd', 'avg_init_win_odd', 'avg_new_draw_kelly',\n",
    "    'avg_new_draw_odd', 'avg_new_draw_rate', 'avg_new_lose_kelly',\n",
    "    'avg_new_lose_odd', 'avg_new_lose_rate', 'avg_new_win_kelly',\n",
    "    'avg_new_win_odd', 'avg_new_win_rate', 'avg_pay_rate',\n",
    "    'dispersion_draw', 'dispersion_lose', 'dispersion_win', 'id_y',\n",
    "    'max_init_draw_odd', 'max_init_lose_odd', 'max_init_win_odd',\n",
    "    'max_new_draw_kelly', 'max_new_draw_odd', 'max_new_draw_rate',\n",
    "    'max_new_lose_kelly', 'max_new_lose_odd', 'max_new_lose_rate',\n",
    "    'max_new_win_kelly', 'max_new_win_odd', 'max_new_win_rate',\n",
    "    'max_pay_rate', 'min_init_draw_odd', 'min_init_lose_odd',\n",
    "    'min_init_win_odd', 'min_new_draw_kelly', 'min_new_draw_odd',\n",
    "    'min_new_draw_rate', 'min_new_lose_kelly', 'min_new_lose_odd',\n",
    "    'min_new_lose_rate', 'min_new_win_kelly', 'min_new_win_odd',\n",
    "    'min_new_win_rate', 'min_pay_rate', 'std_draw', 'std_lose',\n",
    "    'std_win'\n",
    "]\n",
    "    \n",
    "params={\n",
    "    'booster':'gbtree',\n",
    "    # 这里手写数字是0-9，是一个多类的问题，因此采用了multisoft多分类器，\n",
    "    'objective': 'multi:softmax', \n",
    "#     'objective': 'multi:softprob',\n",
    "    'num_class':3, # 类数，与 multisoftmax 并用\n",
    "    \n",
    "    'gamma':0.01,  # 在树的叶子节点下一个分区的最小损失，越大算法模型越保守 。[0:]\n",
    "    \n",
    "    'max_depth':8, # 构建树的深度 [1:]\n",
    "    \n",
    "    #'lambda':450,  # L2 正则项权重\n",
    "    'subsample':0.7, # 采样训练数据，设置为0.5，随机选择一般的数据实例 (0:1]\n",
    "    'colsample_bytree':0.7, # 构建树树时的采样比率 (0:1]\n",
    "    #'min_child_weight':12, # 节点的最少特征数\n",
    "    'silent':1 ,\n",
    "    \n",
    "#     这部分需要调整\n",
    "#     'eta': 0.05, # 如同学习率\n",
    "    'eta': 0.01, # 如同学习率\n",
    "    \n",
    "    \n",
    "    'seed':2018,\n",
    "    'nthread':4,# cpu 线程数,根据自己U的个数适当调整\n",
    "}\n",
    "\n",
    "# t = train_dataset_df[\n",
    "#     (train_dataset_df['win_bet_return'] <= 2) |\n",
    "#     (train_dataset_df['draw_bet_return'] <= 2) |\n",
    "#     (train_dataset_df['lose_bet_return'] <= 2)\n",
    "# ]\n",
    "\n",
    "t = train_dataset_df\n",
    "\n",
    "print(len(t))\n",
    "\n",
    "train_dataset = t[t['year'] < 2019]\n",
    "test_dataset = t[t['year'] == 2019]\n",
    "\n",
    "valid_dataset = test_dataset[test_dataset['month'] < 3]\n",
    "test_dataset = test_dataset[test_dataset['month'] >= 3]\n",
    "\n",
    "xgtrain = xgb.DMatrix(train_dataset[x_columns], label=train_dataset['fix_result'])\n",
    "xgtest = xgb.DMatrix(test_dataset[x_columns], label=test_dataset['fix_result'])\n",
    "xgvalid = xgb.DMatrix(valid_dataset[x_columns], label=valid_dataset['fix_result'])\n",
    "\n",
    "watchlist = [(xgtrain, 'train'),(xgvalid, 'val')]\n",
    "\n",
    "num_rounds = 10000\n",
    "stop_rounds = 100\n",
    "\n",
    "# num_rounds = 10000\n",
    "# stop_rounds = 300\n",
    "\n",
    "\n",
    "model = xgb.train(params, xgtrain, num_rounds, watchlist,early_stopping_rounds=stop_rounds)\n",
    "print(model.best_iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.3452244 , 0.3264327 , 0.3283429 ],\n",
       "       [0.3335006 , 0.3313826 , 0.33511677],\n",
       "       [0.32226524, 0.32644787, 0.35128686],\n",
       "       ...,\n",
       "       [0.32169273, 0.32734713, 0.3509601 ],\n",
       "       [0.32342005, 0.32687503, 0.34970492],\n",
       "       [0.34933007, 0.32826293, 0.32240704]], dtype=float32)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 求可能性的时候用：'objective': 'multi:softprob',\n",
    "\n",
    "pred_probs = model.predict(xgtest, ntree_limit=model.best_iteration)\n",
    "pred_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset['fix_result'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_result(items):\n",
    "    if items[0] <= items[1] and items[0] <= items[2]:\n",
    "        return [1,2]\n",
    "    elif items[1] <= items[0] and items[1] <= items[2]:\n",
    "        return [0,2]\n",
    "    elif items[2] <= items[0] and items[2] <= items[1]:\n",
    "        return [0,1]\n",
    "    \n",
    "fix_results = test_dataset['fix_result'].values\n",
    "\n",
    "results = []\n",
    "for i in range(len(pred_probs)):\n",
    "    items = pred_probs[i]\n",
    "    probs = get_result(items)\n",
    "    \n",
    "    if fix_results[i] in probs:\n",
    "        results.append(1)\n",
    "    else:\n",
    "        results.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7400530503978779"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(results).sum() / len(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4880636604774536"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = model.predict(xgtest, ntree_limit=model.best_iteration)\n",
    "preds\n",
    "\n",
    "accuracy_score(test_dataset['fix_result'], preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM多分类训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leewind/.local/lib/python3.6/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/home/leewind/.local/lib/python3.6/site-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/home/leewind/.local/lib/python3.6/site-packages/ipykernel_launcher.py:20: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n"
     ]
    }
   ],
   "source": [
    "# Seperating Predictors and Outcome values from train and test sets\n",
    "X_train = train_dataset[x_columns]\n",
    "Y_train_label = train_dataset['fix_result'].values.astype(object)\n",
    "\n",
    "X_test = test_dataset[x_columns]\n",
    "Y_test_label = test_dataset['fix_result'].values.astype(object)\n",
    "\n",
    "encoder = preprocessing.LabelEncoder()\n",
    "\n",
    "# encoding train labels \n",
    "encoder.fit(Y_train_label)\n",
    "Y_train = encoder.transform(Y_train_label)\n",
    "\n",
    "# encoding test labels \n",
    "encoder.fit(Y_test_label)\n",
    "Y_test = encoder.transform(Y_test_label)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params_grid = [{'kernel': ['rbf'], 'gamma': [1e-3, 1e-4],\n",
    "#                      'C': [1, 10, 100, 1000]},\n",
    "#                     {'kernel': ['linear'], 'C': [1, 10, 100, 1000]}]\n",
    "\n",
    "params_grid = [{'kernel': ['rbf'], 'gamma': [1e-3, 1e-4], 'C': [10, 100]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=True)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# svm_model = GridSearchCV(SVC(), params_grid, cv=5)\n",
    "# svm_model.fit(X_train_scaled, Y_train)\n",
    "final_model = SVC(C=1, kernel='rbf', degree=3, gamma='auto', verbose=True)\n",
    "final_model.fit(X_train_scaled, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score for SVM: 0.509186\n",
      "Testing  set score for SVM: 0.503095\n"
     ]
    }
   ],
   "source": [
    "# final_model = svm_model.best_estimator_\n",
    "\n",
    "print(\"Training set score for SVM: %f\" % final_model.score(X_train_scaled , Y_train))\n",
    "print(\"Testing  set score for SVM: %f\" % final_model.score(X_test_scaled  , Y_test ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
