{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymysql.cursors\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "import re\n",
    "import datetime\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 训练"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 获取全量的竞彩比赛列表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection = pymysql.connect(host='localhost', user='root', password='breadt@2019', db='breadt-football-ml', charset='utf8mb4', cursorclass=pymysql.cursors.DictCursor)\n",
    "with connection.cursor() as cursor:\n",
    "    sql = 'select * from `breadt_football_game_list`;'\n",
    "    cursor.execute(sql)\n",
    "    rows = cursor.fetchall()\n",
    "    \n",
    "    train_game_list_df = pd.DataFrame(rows)\n",
    "    \n",
    "    connection.close()\n",
    "\n",
    "train_game_list_df['source'] = 'jc'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 获取全量的胜负彩比赛列表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection = pymysql.connect(host='localhost', user='root', password='breadt@2019', db='breadt-football-ml', charset='utf8mb4', cursorclass=pymysql.cursors.DictCursor)\n",
    "with connection.cursor() as cursor:\n",
    "    sql = 'select * from `breadt_lottery_info`;'\n",
    "    cursor.execute(sql)\n",
    "    rows = cursor.fetchall()\n",
    "    \n",
    "    train_lottery_game_list_df = pd.DataFrame(rows)\n",
    "    \n",
    "    connection.close()\n",
    "\n",
    "train_lottery_game_list_df['source'] = 'lottery'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 合并竞彩比赛列表和胜负彩比赛列表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = train_lottery_game_list_df.drop(['issue'], axis=1)\n",
    "df = pd.concat([train_game_list_df, tmp])\n",
    "df = df[['matchid', 'game', 'home_team', 'visit_team', 'gs', 'gd', 'gn', 'time', 'result', 'win_bet_return', 'draw_bet_return', 'lose_bet_return', 'source']]\n",
    "df = df.drop_duplicates(subset=['matchid'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **设定训练范围** 并处理数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# match_group = ['澳超', '英超', '德甲', '德乙', '法甲', '西甲', '意甲', '日职', '英甲', '英冠', '苏超', '法乙', '葡超', '荷甲', '荷乙', '韩K联', '瑞典超', '挪超', '美职', '日乙', '俄超', '比甲', '瑞典甲', '法丙', '挪甲', '英乙', '苏冠', '巴甲', '智利甲', '墨超', '智利乙', '阿甲', '欧冠', '欧罗巴']\n",
    "match_group = ['澳超', '英超', '德甲', '德乙', '法甲', '西甲', '意甲', '日职', '英甲', '英冠', '苏超', '法乙', '葡超', '荷甲', '荷乙', '韩K联', '瑞典超', '挪超', '美职', '日乙', '俄超', '比甲', '瑞典甲', '法丙', '挪甲', '英乙', '苏冠', '巴甲', '智利甲', '墨超', '智利乙', '阿甲']\n",
    "match_df = df[(df['game'].isin(match_group))]\n",
    "match_df = match_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 对team做encode 这个encoder后面预测的时候还会用到\n",
    "teams = list(set(df['home_team'].values) | set(df['visit_team'].values))\n",
    "team_encoder = preprocessing.LabelEncoder()\n",
    "team_encoder.fit(teams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_team(df):\n",
    "    df['home_team_encoder'] = team_encoder.transform(df['home_team'])\n",
    "    df['visit_team_encoder'] = team_encoder.transform(df['visit_team'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 比赛名称encode\n",
    "games = list(set(match_df['game'].values))\n",
    "game_encoder = preprocessing.LabelEncoder()\n",
    "game_encoder.fit(games)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_game(df):\n",
    "    df['game_encoder'] = game_encoder.transform(df['game'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_df['year'] = match_df.apply(lambda row: row.time.year, axis=1)\n",
    "match_df['month'] = match_df.apply(lambda row: row.time.month, axis=1)\n",
    "match_df['day'] = match_df.apply(lambda row: row.time.day, axis=1)\n",
    "match_df['fix_result'] = match_df.apply(lambda row: int(row.result) if row.result < 3 else 2, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_df = encode_team(match_df)\n",
    "match_df = encode_game(match_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 43477 entries, 1 to 12650\n",
      "Data columns (total 20 columns):\n",
      "matchid               43477 non-null int64\n",
      "game                  43477 non-null object\n",
      "home_team             43477 non-null object\n",
      "visit_team            43477 non-null object\n",
      "gs                    43477 non-null int64\n",
      "gd                    43477 non-null int64\n",
      "gn                    43477 non-null int64\n",
      "time                  43477 non-null datetime64[ns]\n",
      "result                43477 non-null int64\n",
      "win_bet_return        43477 non-null float64\n",
      "draw_bet_return       43477 non-null float64\n",
      "lose_bet_return       43477 non-null float64\n",
      "source                43477 non-null object\n",
      "year                  43477 non-null int64\n",
      "month                 43477 non-null int64\n",
      "day                   43477 non-null int64\n",
      "fix_result            43477 non-null int64\n",
      "home_team_encoder     43477 non-null int64\n",
      "visit_team_encoder    43477 non-null int64\n",
      "game_encoder          43477 non-null int64\n",
      "dtypes: datetime64[ns](1), float64(3), int64(12), object(4)\n",
      "memory usage: 7.0+ MB\n"
     ]
    }
   ],
   "source": [
    "match_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 获取特征数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection = pymysql.connect(host='localhost', user='root', password='breadt@2019', db='breadt-football-ml', charset='utf8mb4', cursorclass=pymysql.cursors.DictCursor)\n",
    "with connection.cursor() as cursor:\n",
    "    sql = 'select * from `breadt_football_recent_feature_info`;'\n",
    "    cursor.execute(sql)\n",
    "    rows = cursor.fetchall()\n",
    "    \n",
    "    train_feature_df = pd.DataFrame(rows)\n",
    "    \n",
    "    connection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def take_goal_info(prefix, df):\n",
    "    target_cols = [\n",
    "        '_0_1_gd', \n",
    "        '_0_1_gs', \n",
    "        '_0_gd', \n",
    "        '_0_gs', \n",
    "        '_1_gd', \n",
    "        '_1_gs',\n",
    "        '_2_3_gd', \n",
    "        '_2_3_gs', \n",
    "        '_2_gd', \n",
    "        '_2_gs', \n",
    "        '_3_gd', \n",
    "        '_3_gs',\n",
    "        '_4_gd', \n",
    "        '_4_gs', \n",
    "        '_5_gd', \n",
    "        '_5_gs', \n",
    "        '_6_gd', \n",
    "        '_6_gs',\n",
    "        '_7_gd', \n",
    "        '_7_gs', \n",
    "        '_ab_4_gd', \n",
    "        '_ab_4_gs',\n",
    "        '_abs_draw', \n",
    "        '_abs_lose', \n",
    "        '_abs_win']\n",
    "\n",
    "    for k in target_cols:\n",
    "        df[prefix + k + '_rate'] = df[prefix + k] / df[prefix + '_count']\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def take_goal_pref_info(prefix, df):\n",
    "    target_cols = [\n",
    "        '_draw', '_g', '_gd',\n",
    "        '_gs', '_lose', '_win',\n",
    "    ]\n",
    "\n",
    "    for k in target_cols:\n",
    "        df[prefix + k + '_rate'] = df[prefix + k] / df[prefix + '_count']\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feature_df = take_goal_info('h', train_feature_df)\n",
    "train_feature_df = take_goal_info('v', train_feature_df)\n",
    "\n",
    "train_feature_df = take_goal_pref_info('h_host', train_feature_df)\n",
    "train_feature_df = take_goal_pref_info('v_visit', train_feature_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feature_df['h_avg_abs_gs'] = train_feature_df['h_abs_gs'].sum() / train_feature_df['h_count'].sum()\n",
    "train_feature_df['h_avg_abs_gd'] = train_feature_df['h_abs_gd'].sum() / train_feature_df['h_count'].sum()\n",
    "train_feature_df['v_avg_abs_gs'] = train_feature_df['v_abs_gs'].sum() / train_feature_df['v_count'].sum()\n",
    "train_feature_df['v_avg_abs_gd'] = train_feature_df['v_abs_gd'].sum() / train_feature_df['v_count'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feature_df['h_avg_abs_win'] = train_feature_df['h_abs_win'].sum() / train_feature_df['h_count'].sum()\n",
    "train_feature_df['h_avg_abs_draw'] = train_feature_df['h_abs_draw'].sum() / train_feature_df['h_count'].sum()\n",
    "train_feature_df['h_avg_abs_lose'] = train_feature_df['h_abs_lose'].sum() / train_feature_df['h_count'].sum()\n",
    "\n",
    "train_feature_df['v_avg_abs_win'] = train_feature_df['v_abs_win'].sum() / train_feature_df['v_count'].sum()\n",
    "train_feature_df['v_avg_abs_draw'] = train_feature_df['v_abs_draw'].sum() / train_feature_df['v_count'].sum()\n",
    "train_feature_df['v_avg_abs_lose'] = train_feature_df['v_abs_lose'].sum() / train_feature_df['v_count'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 合并训练数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 41306 entries, 0 to 43283\n",
      "Columns: 171 entries, matchid to v_avg_abs_lose\n",
      "dtypes: datetime64[ns](1), float64(154), int64(12), object(4)\n",
      "memory usage: 54.2+ MB\n"
     ]
    }
   ],
   "source": [
    "train_dataset_df = pd.merge(match_df, train_feature_df, on='matchid', how='left')\n",
    "train_dataset_df = train_dataset_df.dropna()\n",
    "train_dataset_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['matchid', 'game', 'home_team', 'visit_team', 'gs', 'gd', 'gn',\n",
       "       'time', 'result', 'win_bet_return', 'draw_bet_return',\n",
       "       'lose_bet_return', 'source', 'year', 'month', 'day', 'fix_result',\n",
       "       'home_team_encoder', 'visit_team_encoder', 'game_encoder',\n",
       "       'h_0_1_gd', 'h_0_1_gs', 'h_0_gd', 'h_0_gs', 'h_1_gd', 'h_1_gs',\n",
       "       'h_2_3_gd', 'h_2_3_gs', 'h_2_gd', 'h_2_gs', 'h_3_gd', 'h_3_gs',\n",
       "       'h_4_gd', 'h_4_gs', 'h_5_gd', 'h_5_gs', 'h_6_gd', 'h_6_gs',\n",
       "       'h_7_gd', 'h_7_gs', 'h_ab_4_gd', 'h_ab_4_gs', 'h_abs_avg_g',\n",
       "       'h_abs_avg_gd', 'h_abs_avg_gs', 'h_abs_draw', 'h_abs_g',\n",
       "       'h_abs_gd', 'h_abs_gs', 'h_abs_lose', 'h_abs_win', 'h_count',\n",
       "       'h_host_count', 'h_host_draw', 'h_host_g', 'h_host_gd',\n",
       "       'h_host_gs', 'h_host_lose', 'h_host_win', 'id', 'v_0_1_gd',\n",
       "       'v_0_1_gs', 'v_0_gd', 'v_0_gs', 'v_1_gd', 'v_1_gs', 'v_2_3_gd',\n",
       "       'v_2_3_gs', 'v_2_gd', 'v_2_gs', 'v_3_gd', 'v_3_gs', 'v_4_gd',\n",
       "       'v_4_gs', 'v_5_gd', 'v_5_gs', 'v_6_gd', 'v_6_gs', 'v_7_gd',\n",
       "       'v_7_gs', 'v_ab_4_gd', 'v_ab_4_gs', 'v_abs_avg_g', 'v_abs_avg_gd',\n",
       "       'v_abs_avg_gs', 'v_abs_draw', 'v_abs_g', 'v_abs_gd', 'v_abs_gs',\n",
       "       'v_abs_lose', 'v_abs_win', 'v_count', 'v_visit_count',\n",
       "       'v_visit_draw', 'v_visit_g', 'v_visit_gd', 'v_visit_gs',\n",
       "       'v_visit_lose', 'v_visit_win', 'h_0_1_gd_rate', 'h_0_1_gs_rate',\n",
       "       'h_0_gd_rate', 'h_0_gs_rate', 'h_1_gd_rate', 'h_1_gs_rate',\n",
       "       'h_2_3_gd_rate', 'h_2_3_gs_rate', 'h_2_gd_rate', 'h_2_gs_rate',\n",
       "       'h_3_gd_rate', 'h_3_gs_rate', 'h_4_gd_rate', 'h_4_gs_rate',\n",
       "       'h_5_gd_rate', 'h_5_gs_rate', 'h_6_gd_rate', 'h_6_gs_rate',\n",
       "       'h_7_gd_rate', 'h_7_gs_rate', 'h_ab_4_gd_rate', 'h_ab_4_gs_rate',\n",
       "       'h_abs_draw_rate', 'h_abs_lose_rate', 'h_abs_win_rate',\n",
       "       'v_0_1_gd_rate', 'v_0_1_gs_rate', 'v_0_gd_rate', 'v_0_gs_rate',\n",
       "       'v_1_gd_rate', 'v_1_gs_rate', 'v_2_3_gd_rate', 'v_2_3_gs_rate',\n",
       "       'v_2_gd_rate', 'v_2_gs_rate', 'v_3_gd_rate', 'v_3_gs_rate',\n",
       "       'v_4_gd_rate', 'v_4_gs_rate', 'v_5_gd_rate', 'v_5_gs_rate',\n",
       "       'v_6_gd_rate', 'v_6_gs_rate', 'v_7_gd_rate', 'v_7_gs_rate',\n",
       "       'v_ab_4_gd_rate', 'v_ab_4_gs_rate', 'v_abs_draw_rate',\n",
       "       'v_abs_lose_rate', 'v_abs_win_rate', 'h_host_draw_rate',\n",
       "       'h_host_g_rate', 'h_host_gd_rate', 'h_host_gs_rate',\n",
       "       'h_host_lose_rate', 'h_host_win_rate', 'v_visit_draw_rate',\n",
       "       'v_visit_g_rate', 'v_visit_gd_rate', 'v_visit_gs_rate',\n",
       "       'v_visit_lose_rate', 'v_visit_win_rate', 'h_avg_abs_gs',\n",
       "       'h_avg_abs_gd', 'v_avg_abs_gs', 'v_avg_abs_gd', 'h_avg_abs_win',\n",
       "       'h_avg_abs_draw', 'h_avg_abs_lose', 'v_avg_abs_win',\n",
       "       'v_avg_abs_draw', 'v_avg_abs_lose'], dtype=object)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset_df.columns.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## xgb训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[122]\ttrain-merror:0.379858\tval-merror:0.514963\n",
      "[123]\ttrain-merror:0.379807\tval-merror:0.516209\n",
      "[124]\ttrain-merror:0.379705\tval-merror:0.516209\n",
      "[125]\ttrain-merror:0.379526\tval-merror:0.514963\n",
      "[126]\ttrain-merror:0.379245\tval-merror:0.514963\n",
      "[127]\ttrain-merror:0.379041\tval-merror:0.514963\n",
      "[128]\ttrain-merror:0.378454\tval-merror:0.514963\n",
      "[129]\ttrain-merror:0.378403\tval-merror:0.513716\n",
      "[130]\ttrain-merror:0.377739\tval-merror:0.513716\n",
      "Stopping. Best iteration:\n",
      "[30]\ttrain-merror:0.400388\tval-merror:0.503741\n",
      "\n",
      "30\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "x_columns = [\n",
    "    'win_bet_return', 'draw_bet_return', 'lose_bet_return', \n",
    "    'year', 'month',\n",
    "    'home_team_encoder', 'visit_team_encoder', 'game_encoder',\n",
    "    \n",
    "    'h_avg_abs_gs',\n",
    "    'h_avg_abs_gd', 'v_avg_abs_gs', 'v_avg_abs_gd', 'h_avg_abs_win',\n",
    "    'h_avg_abs_draw', 'h_avg_abs_lose', 'v_avg_abs_win',\n",
    "    'v_avg_abs_draw', 'v_avg_abs_lose',\n",
    "    \n",
    "    'h_0_1_gd', \n",
    "    'h_0_1_gs', \n",
    "    'h_0_gd', \n",
    "    'h_0_gs', \n",
    "    'h_1_gd', \n",
    "    'h_1_gs',\n",
    "    'h_2_3_gd', \n",
    "    'h_2_3_gs', \n",
    "    'h_2_gd', 'h_2_gs', 'h_3_gd', 'h_3_gs',\n",
    "    'h_4_gd', 'h_4_gs', 'h_5_gd', 'h_5_gs', 'h_6_gd', 'h_6_gs',\n",
    "    'h_7_gd', 'h_7_gs', 'h_ab_4_gd', 'h_ab_4_gs', 'h_abs_avg_g',\n",
    "    'h_abs_avg_gd', 'h_abs_avg_gs', 'h_abs_draw', 'h_abs_g',\n",
    "    'h_abs_gd', 'h_abs_gs', 'h_abs_lose', 'h_abs_win', 'h_count',\n",
    "    'h_host_count', 'h_host_draw', 'h_host_g', 'h_host_gd',\n",
    "    'h_host_gs', 'h_host_lose', 'h_host_win', \n",
    "    \n",
    "    'v_0_1_gd',\n",
    "    'v_0_1_gs', 'v_0_gd', 'v_0_gs', 'v_1_gd', 'v_1_gs', 'v_2_3_gd',\n",
    "    'v_2_3_gs', 'v_2_gd', 'v_2_gs', 'v_3_gd', 'v_3_gs', 'v_4_gd',\n",
    "    'v_4_gs', 'v_5_gd', 'v_5_gs', 'v_6_gd', 'v_6_gs', 'v_7_gd',\n",
    "    'v_7_gs', 'v_ab_4_gd', 'v_ab_4_gs', 'v_abs_avg_g', 'v_abs_avg_gd',\n",
    "    'v_abs_avg_gs', 'v_abs_draw', 'v_abs_g', 'v_abs_gd', 'v_abs_gs',\n",
    "    'v_abs_lose', 'v_abs_win', \n",
    "    \n",
    "    'v_count', \n",
    "    'v_visit_count',\n",
    "    'v_visit_draw', 'v_visit_g', 'v_visit_gd', 'v_visit_gs',\n",
    "    'v_visit_lose', 'v_visit_win',\n",
    "    \n",
    "    'h_0_1_gd_rate', 'h_0_1_gs_rate',\n",
    "    'h_0_gd_rate', 'h_0_gs_rate', 'h_1_gd_rate', 'h_1_gs_rate',\n",
    "    'h_2_3_gd_rate', 'h_2_3_gs_rate', 'h_2_gd_rate', 'h_2_gs_rate',\n",
    "    'h_3_gd_rate', 'h_3_gs_rate', 'h_4_gd_rate', 'h_4_gs_rate',\n",
    "    'h_5_gd_rate', 'h_5_gs_rate', 'h_6_gd_rate', 'h_6_gs_rate',\n",
    "    'h_7_gd_rate', 'h_7_gs_rate', 'h_ab_4_gd_rate', 'h_ab_4_gs_rate',\n",
    "    'h_abs_draw_rate', 'h_abs_lose_rate', 'h_abs_win_rate',\n",
    "    'v_0_1_gd_rate', 'v_0_1_gs_rate', 'v_0_gd_rate', 'v_0_gs_rate',\n",
    "    'v_1_gd_rate', 'v_1_gs_rate', 'v_2_3_gd_rate', 'v_2_3_gs_rate',\n",
    "    'v_2_gd_rate', 'v_2_gs_rate', 'v_3_gd_rate', 'v_3_gs_rate',\n",
    "    'v_4_gd_rate', 'v_4_gs_rate', 'v_5_gd_rate', 'v_5_gs_rate',\n",
    "    'v_6_gd_rate', 'v_6_gs_rate', 'v_7_gd_rate', 'v_7_gs_rate',\n",
    "    \n",
    "    'v_ab_4_gd_rate', \n",
    "    'v_ab_4_gs_rate', \n",
    "    'v_abs_draw_rate',\n",
    "    'v_abs_lose_rate', \n",
    "    'v_abs_win_rate',\n",
    "    'h_host_draw_rate',\n",
    "    'h_host_g_rate', \n",
    "    'h_host_gd_rate', \n",
    "    'h_host_gs_rate',\n",
    "    'h_host_lose_rate', \n",
    "    'h_host_win_rate', \n",
    "    'v_visit_draw_rate',\n",
    "    'v_visit_g_rate', \n",
    "    'v_visit_gd_rate', \n",
    "    'v_visit_gs_rate',\n",
    "    'v_visit_lose_rate', \n",
    "    'v_visit_win_rate'\n",
    "]\n",
    "    \n",
    "params={\n",
    "    'booster':'gbtree',\n",
    "    # 这里手写数字是0-9，是一个多类的问题，因此采用了multisoft多分类器，\n",
    "    'objective': 'multi:softmax', \n",
    "#     'objective': 'multi:softprob',\n",
    "    'num_class':3, # 类数，与 multisoftmax 并用\n",
    "    \n",
    "    'gamma':0.01,  # 在树的叶子节点下一个分区的最小损失，越大算法模型越保守 。[0:]\n",
    "    \n",
    "    'max_depth':10, # 构建树的深度 [1:]\n",
    "    \n",
    "    #'lambda':450,  # L2 正则项权重\n",
    "    'subsample':0.7, # 采样训练数据，设置为0.5，随机选择一般的数据实例 (0:1]\n",
    "    'colsample_bytree':0.7, # 构建树树时的采样比率 (0:1]\n",
    "    #'min_child_weight':12, # 节点的最少特征数\n",
    "    'silent':1 ,\n",
    "    \n",
    "#     这部分需要调整\n",
    "#     'eta': 0.05, # 如同学习率\n",
    "    'eta': 0.01, # 如同学习率\n",
    "    \n",
    "    \n",
    "    'seed':2018,\n",
    "    'nthread':4,# cpu 线程数,根据自己U的个数适当调整\n",
    "}\n",
    "\n",
    "# t = train_dataset_df[\n",
    "#     (train_dataset_df['win_bet_return'] <= 2) |\n",
    "#     (train_dataset_df['draw_bet_return'] <= 2) |\n",
    "#     (train_dataset_df['lose_bet_return'] <= 2)\n",
    "# ]\n",
    "\n",
    "t = train_dataset_df\n",
    "\n",
    "print(len(t))\n",
    "\n",
    "train_dataset = t[t['year'] < 2019]\n",
    "test_dataset = t[t['year'] == 2019]\n",
    "\n",
    "valid_dataset = test_dataset[test_dataset['month'] < 3]\n",
    "test_dataset = test_dataset[test_dataset['month'] >= 3]\n",
    "\n",
    "xgtrain = xgb.DMatrix(train_dataset[x_columns], label=train_dataset['fix_result'])\n",
    "xgtest = xgb.DMatrix(test_dataset[x_columns], label=test_dataset['fix_result'])\n",
    "xgvalid = xgb.DMatrix(valid_dataset[x_columns], label=valid_dataset['fix_result'])\n",
    "\n",
    "watchlist = [(xgtrain, 'train'),(xgvalid, 'val')]\n",
    "\n",
    "num_rounds = 10000\n",
    "stop_rounds = 100\n",
    "\n",
    "# num_rounds = 10000\n",
    "# stop_rounds = 300\n",
    "\n",
    "\n",
    "model = xgb.train(params, xgtrain, num_rounds, watchlist,early_stopping_rounds=stop_rounds)\n",
    "print(model.best_iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.3329681 , 0.32910088, 0.337931  ],\n",
       "       [0.33841   , 0.32967126, 0.33191878],\n",
       "       [0.35295928, 0.32484668, 0.322194  ],\n",
       "       ...,\n",
       "       [0.32852158, 0.33240506, 0.33907336],\n",
       "       [0.32646173, 0.3299921 , 0.34354618],\n",
       "       [0.32665062, 0.32860482, 0.3447446 ]], dtype=float32)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 求可能性的时候用：'objective': 'multi:softprob',\n",
    "\n",
    "pred_probs = model.predict(xgtest, ntree_limit=model.best_iteration)\n",
    "pred_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 0, 0, ..., 1, 2, 0])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset['fix_result'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_result(items):\n",
    "    if items[0] <= items[1] and items[0] <= items[2]:\n",
    "        return [1,2]\n",
    "    elif items[1] <= items[0] and items[1] <= items[2]:\n",
    "        return [0,2]\n",
    "    elif items[2] <= items[0] and items[2] <= items[1]:\n",
    "        return [0,1]\n",
    "    \n",
    "fix_results = test_dataset['fix_result'].values\n",
    "\n",
    "results = []\n",
    "for i in range(len(pred_probs)):\n",
    "    items = pred_probs[i]\n",
    "    probs = get_result(items)\n",
    "    \n",
    "    if fix_results[i] in probs:\n",
    "        results.append(1)\n",
    "    else:\n",
    "        results.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7742175856929955"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(results).sum() / len(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = model.predict(xgtest, ntree_limit=model.best_iteration)\n",
    "preds\n",
    "\n",
    "accuracy_score(test_dataset['fix_result'], preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM多分类训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leewind/.local/lib/python3.6/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/home/leewind/.local/lib/python3.6/site-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/home/leewind/.local/lib/python3.6/site-packages/ipykernel_launcher.py:20: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n"
     ]
    }
   ],
   "source": [
    "# Seperating Predictors and Outcome values from train and test sets\n",
    "X_train = train_dataset[x_columns]\n",
    "Y_train_label = train_dataset['fix_result'].values.astype(object)\n",
    "\n",
    "X_test = test_dataset[x_columns]\n",
    "Y_test_label = test_dataset['fix_result'].values.astype(object)\n",
    "\n",
    "encoder = preprocessing.LabelEncoder()\n",
    "\n",
    "# encoding train labels \n",
    "encoder.fit(Y_train_label)\n",
    "Y_train = encoder.transform(Y_train_label)\n",
    "\n",
    "# encoding test labels \n",
    "encoder.fit(Y_test_label)\n",
    "Y_test = encoder.transform(Y_test_label)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params_grid = [{'kernel': ['rbf'], 'gamma': [1e-3, 1e-4],\n",
    "#                      'C': [1, 10, 100, 1000]},\n",
    "#                     {'kernel': ['linear'], 'C': [1, 10, 100, 1000]}]\n",
    "\n",
    "params_grid = [{'kernel': ['rbf'], 'gamma': [1e-3, 1e-4], 'C': [10, 100]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_model = GridSearchCV(SVC(), params_grid, cv=5)\n",
    "svm_model.fit(X_train_scaled, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = svm_model.best_estimator_\n",
    "\n",
    "print(\"Training set score for SVM: %f\" % final_model.score(X_train_scaled , Y_train))\n",
    "print(\"Testing  set score for SVM: %f\" % final_model.score(X_test_scaled  , Y_test ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
